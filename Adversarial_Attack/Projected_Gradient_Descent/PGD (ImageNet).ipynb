{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projected Gradient Descent\n",
    "\n",
    "- Author: Tootouch (Jaehyuk Heo)\n",
    "\n",
    "- Towards Deep Learning Models Resistant to Adversarial Attacks [ [paper](https://arxiv.org/abs/1706.06083) ]\n",
    "- torchattacks [ [doc](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/37654013/136537549-e31ba553-67ce-43b5-ad36-479e4fb9021d.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torchattacks\n",
    "# pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchattacks.attack import Attack\n",
    "\n",
    "import timm\n",
    "from timm.data import create_loader, create_dataset\n",
    "from timm.data.transforms import _pil_interp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    dataset      = 'Imagenet'\n",
    "    data         = '/datasets/Imagenet/ILSVRC/Data/CLS-LOC/'\n",
    "    split        = 'val'\n",
    "    img_size     = 224\n",
    "    batch_size   = 512\n",
    "    num_workers  = 8\n",
    "    \n",
    "args = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms_imagenet_eval(img_size, crop_pct, interpolation):\n",
    "\n",
    "    # scaling image for cropping\n",
    "    if isinstance(img_size, (tuple, list)):\n",
    "        assert len(img_size) == 2\n",
    "        if img_size[-1] == img_size[-2]:\n",
    "            # fall-back to older behaviour so Resize scales to shortest edge if target is square\n",
    "            scale_size = int(math.floor(img_size[0] / crop_pct))\n",
    "        else:\n",
    "            scale_size = tuple([int(x / crop_pct) for x in img_size])\n",
    "    else:\n",
    "        scale_size = int(math.floor(img_size / crop_pct))\n",
    "\n",
    "    # transforms list\n",
    "    tfl = [\n",
    "        transforms.Resize(scale_size, _pil_interp(interpolation)),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    "\n",
    "    return transforms.Compose(tfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_eval = transforms_imagenet_eval(\n",
    "    img_size      = args.img_size,\n",
    "    crop_pct      = model.default_cfg['crop_pct'],\n",
    "    interpolation = model.default_cfg['interpolation']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(root=args.data, name=args.dataset, split=args.split)\n",
    "dataset.transform = transform_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=args.batch_size, num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalize, self).__init__()\n",
    "        self.register_buffer('mean', torch.Tensor(mean))\n",
    "        self.register_buffer('std', torch.Tensor(std))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        mean = self.mean.view(1, 3, 1, 1)\n",
    "        std = self.std.view(1, 3, 1, 1)\n",
    "        return (input - mean) / std\n",
    "    \n",
    "model = nn.Sequential(\n",
    "    Normalize(mean=model.default_cfg['mean'], std=model.default_cfg['std']),\n",
    "    model\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "    return [correct[:k].reshape(-1).float().sum(0) * 100. / batch_size for k in topk]\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for batch_idx, (input, target) in enumerate(loader):\n",
    "            target = target.cuda()\n",
    "            input = input.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output.detach(), target, topk=(1, 5))\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(acc1.item(), input.size(0))\n",
    "            top5.update(acc5.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "        \n",
    "    print(\n",
    "        'Time: {batch_time.sum:.3f}s ({batch_time.avg:.3f}s, {rate_avg:>6.2f}/s) '\n",
    "        'Loss: {loss.avg:>6.4f} '\n",
    "        'Acc@1: {top1.avg:>7.3f} '\n",
    "        'Acc@5: {top5.avg:>7.3f}'.format(\n",
    "        batch_time=batch_time,\n",
    "        rate_avg=input.size(0) / batch_time.avg,\n",
    "        loss=losses, top1=top1, top5=top5)\n",
    "    )\n",
    "    \n",
    "    return batch_time, losses, top1, top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 82.344s (0.840s, 399.89/s) Loss: 1.0520 Acc@1:  78.600 Acc@5:  94.240\n"
     ]
    }
   ],
   "source": [
    "batch_time, losses, top1, top5 = validate(model, loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FGSM(Fast Gradient Sign Method)**\n",
    "\n",
    "$$x+\\epsilon(\\nabla_x L(\\delta, x, y))$$\n",
    "\n",
    "**PGD(Projected Gradient Descent)**\n",
    "\n",
    "$$x^{t+1}=\\prod_{x+S}(x^t+\\alpha \\text{sgn}(\\nabla_x L(\\delta, x, y)))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/37654013/136537857-3a458af5-9a97-4cb7-bf01-1e7a61ac916a.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGD(Attack):\n",
    "    r\"\"\"\n",
    "    PGD in the paper 'Towards Deep Learning Models Resistant to Adversarial Attacks'\n",
    "    [https://arxiv.org/abs/1706.06083]\n",
    "    Distance Measure : Linf\n",
    "    Arguments:\n",
    "        model (nn.Module): model to attack.\n",
    "        eps (float): maximum perturbation. (Default: 0.3)\n",
    "        alpha (float): step size. (Default: 2/255)\n",
    "        steps (int): number of steps. (Default: 40)\n",
    "        random_start (bool): using random initialization of delta. (Default: True)\n",
    "    Shape:\n",
    "        - images: :math:`(N, C, H, W)` where `N = number of batches`, `C = number of channels`,        `H = height` and `W = width`. It must have a range [0, 1].\n",
    "        - labels: :math:`(N)` where each value :math:`y_i` is :math:`0 \\leq y_i \\leq` `number of labels`.\n",
    "        - output: :math:`(N, C, H, W)`.\n",
    "    Examples::\n",
    "        >>> attack = torchattacks.PGD(model, eps=8/255, alpha=1/255, steps=40, random_start=True)\n",
    "        >>> adv_images = attack(images, labels)\n",
    "    \"\"\"\n",
    "    def __init__(self, model, eps=0.3,\n",
    "                 alpha=2/255, steps=40, random_start=True):\n",
    "        super().__init__(\"PGD\", model)\n",
    "        self.eps = eps\n",
    "        self.alpha = alpha\n",
    "        self.steps = steps\n",
    "        self.random_start = random_start\n",
    "        self._supported_mode = ['default', 'targeted']\n",
    "\n",
    "    def forward(self, images, labels):\n",
    "        r\"\"\"\n",
    "        Overridden.\n",
    "        \"\"\"\n",
    "        images = images.clone().detach().to(self.device)\n",
    "        labels = labels.clone().detach().to(self.device)\n",
    "\n",
    "        if self._targeted:\n",
    "            target_labels = self._get_target_label(images, labels)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        adv_images = images.clone().detach()\n",
    "\n",
    "        if self.random_start:\n",
    "            # Starting at a uniformly random point\n",
    "            adv_images = adv_images + torch.empty_like(adv_images).uniform_(-self.eps, self.eps)\n",
    "            adv_images = torch.clamp(adv_images, min=0, max=1).detach()\n",
    "\n",
    "        for _ in range(self.steps):\n",
    "            adv_images.requires_grad = True\n",
    "            outputs = self.model(adv_images)\n",
    "\n",
    "            # Calculate loss\n",
    "            if self._targeted:\n",
    "                cost = -loss(outputs, target_labels)\n",
    "            else:\n",
    "                cost = loss(outputs, labels)\n",
    "\n",
    "            # Update adversarial images\n",
    "            grad = torch.autograd.grad(cost, adv_images,\n",
    "                                       retain_graph=False, create_graph=False)[0]\n",
    "\n",
    "            adv_images = adv_images.detach() + self.alpha*grad.sign()\n",
    "            delta = torch.clamp(adv_images - images, min=-self.eps, max=self.eps)\n",
    "            adv_images = torch.clamp(images + delta, min=0, max=1).detach()\n",
    "\n",
    "        return adv_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "atk = PGD(model, eps=8/255, alpha=2/255, steps=40, random_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=32, num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Image & Predicted Label\n",
      "----------------------------------------------------------------------\n",
      "PGD(model_name=Sequential, device=cuda:0, eps=0.03137254901960784, alpha=0.00784313725490196, steps=40, random_start=True, attack_mode=default, return_type=float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8851625bd8b24605b5962357b96b777c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1563), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total elapsed time (sec): 11231.93\n",
      "Robust accuracy: 0.01 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Adversarial Image & Predicted Label\")\n",
    "    \n",
    "print(\"-\"*70)\n",
    "print(atk)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "start = time.time()\n",
    "for images, labels in tqdm(loader):\n",
    "\n",
    "    adv_images = atk(images, labels)\n",
    "    labels = labels.cuda()\n",
    "    outputs = model(adv_images)\n",
    "\n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "\n",
    "    total += images.size(0)\n",
    "    correct += (pre == labels).sum()\n",
    "\n",
    "print('Total elapsed time (sec): %.2f' % (time.time() - start))\n",
    "print('Robust accuracy: %.2f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 minutes\n"
     ]
    }
   ],
   "source": [
    "print('{} minutes'.format(round(11231.93 / 60)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
