{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:44.764083Z",
     "start_time": "2022-07-11T07:01:43.301607Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import flow_ssl\n",
    "from experiments.train_flows import utils\n",
    "\n",
    "import torch\n",
    "from torch import distributions\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.utils import _pair, _quadruple\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import SVHN\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dataloader import get_transform, get_loader\n",
    "from utils import seed_everything, get_percentile, schedule, MedianPool2d, AverageMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:44.775507Z",
     "start_time": "2022-07-11T07:01:44.765834Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_args(notebook=False, print_=False):\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--dataset', type=str, default=\"cifar10\", metavar='DATA',\n",
    "                        help='Dataset name (lower case, default: cifar0),\\\n",
    "                        opt : [cifar10, svhn, mnist, fmnist]')\n",
    "    parser.add_argument('--data_path', type=str, default=None, metavar='PATH',\n",
    "                        help='path to datasets location (default: None)')\n",
    "    \n",
    "    parser.add_argument('--ood_dataset', type=str, default=None, required=False, metavar='DATA',\n",
    "                        help='OOD dataset name (default: None)')\n",
    "    parser.add_argument('--ood_data_path', type=str, default=None, metavar='PATH',\n",
    "                        help='path to ood datasets location (default: None)')\n",
    "    \n",
    "    parser.add_argument('--logdir', type=str, default=None, metavar='PATH',\n",
    "                        help='path to log directory (default: None)')\n",
    "    parser.add_argument('--ckptdir', type=str, default=None, metavar='PATH',\n",
    "                        help='path to ckpt directory (default: None)')\n",
    "\n",
    "    parser.add_argument('--batch_size', default=32, type=int, help='Batch size')\n",
    "    parser.add_argument('--lr', default=1e-3, type=float, help='Learning rate')\n",
    "    parser.add_argument('--max_grad_norm', type=float, default=100., help='Max gradient norm for clipping')\n",
    "    parser.add_argument('--num_epochs', default=101, type=int, help='Number of epochs to train')\n",
    "    parser.add_argument('--num_samples', default=20, type=int, help='Number of samples at test time')\n",
    "    parser.add_argument('--num_workers', default=8, type=int, help='Number of data loader threads')\n",
    "    parser.add_argument('--resume',  type=str, default=None, metavar='PATH', help='path to ckpt')\n",
    "    parser.add_argument('--weight_decay', default=5e-5, type=float,\n",
    "                        help='L2 regularization (only applied to the weight norm scale factors)')\n",
    "\n",
    "    parser.add_argument('--save_freq', default=25, type=int, help='frequency of saving ckpts')\n",
    "    parser.add_argument('--negative_val', default=-100_000, type=int, help='Negative loss threshold')\n",
    "    \n",
    "    parser.add_argument('--flow', type=str, default=\"RealNVP\", help=\"Flow model to use (default: RealNVP) \\\n",
    "                        choices=['RealNVP', 'Glow', 'RealNVPNewMask', 'RealNVPNewMask2', 'RealNVPSmall']\")\n",
    "    parser.add_argument('--num_blocks', default=8, type=int, help='number of blocks in ResNet')\n",
    "    parser.add_argument('--num_scales', default=3, type=int, help='number of scales in multi-layer architecture')\n",
    "    parser.add_argument('--num_mid_channels', default=64, type=int, help='number of channels \\\n",
    "                                                                          in coupling layer parametrizing network')\n",
    "    parser.add_argument('--no_batchnorm', action='store_true')\n",
    "    parser.add_argument('--st_type', choices=['highway', 'resnet', 'convnet'], default='resnet')\n",
    "    parser.add_argument('--aug', action='store_true')\n",
    "    parser.add_argument('--init_zeros', action='store_true')\n",
    "    parser.add_argument('--optim', choices=['Adam', 'RMSprop'], default='Adam')\n",
    "    parser.add_argument('--lr_anneal', action='store_true')\n",
    "\n",
    "    args = parser.parse_args([]) if notebook else parser.parse_args()\n",
    "    \n",
    "    if print_:\n",
    "        parser.print_help()\n",
    "        \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:44.781265Z",
     "start_time": "2022-07-11T07:01:44.776774Z"
    }
   },
   "outputs": [],
   "source": [
    "args = parse_args(True, print_=False)\n",
    "\n",
    "args.data_path = 'experiments/datasets'\n",
    "args.ood_data_path = 'experiments/datasets'\n",
    "args.ood_dataset = 'svhn'\n",
    "\n",
    "args.ckptdir = 'ckpt_onlyIn'\n",
    "args.logdir = 'log_onlyIn'\n",
    "args.lr_anneal = True\n",
    "args.lr = 5e-5\n",
    "args.save_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:44.807544Z",
     "start_time": "2022-07-11T07:01:44.782332Z"
    }
   },
   "outputs": [],
   "source": [
    "case = f'OnlyIn_IN-{args.dataset}_OOD-{args.ood_dataset}_epochs-{args.num_epochs}_flow-{args.flow}_lr-{args.lr}_anneal-{args.lr_anneal}_\\nblocks-{args.num_blocks}_nscales-{args.num_scales}_st-{args.st_type}_aug-{args.aug}_optim-{args.optim}'\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:44.811384Z",
     "start_time": "2022-07-11T07:01:44.808612Z"
    }
   },
   "outputs": [],
   "source": [
    "use_wandb = False\n",
    "if use_wandb:\n",
    "    wandb.init(project=\"NF_neg_training\", entity=\"jskim0406\", name=f'{case}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:44.816163Z",
     "start_time": "2022-07-11T07:01:44.812402Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:44.819145Z",
     "start_time": "2022-07-11T07:01:44.817233Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_train_c10, transform_test_c10, img_shape = get_transform(args, 'cifar10')\n",
    "transform_train_svhn, transform_test_svhn, _ = get_transform(args, 'svhn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:46.054343Z",
     "start_time": "2022-07-11T07:01:44.820821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader, _ = get_loader(args, 'cifar10', transform_train_c10, transform_test_c10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:48.508023Z",
     "start_time": "2022-07-11T07:01:46.055685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: experiments/datasets/train_32x32.mat\n",
      "Using downloaded and verified file: experiments/datasets/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "ood_trainloader, ood_testloader, _ = get_loader(args, 'svhn', transform_train_svhn, transform_test_svhn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:48.511022Z",
     "start_time": "2022-07-11T07:01:48.509040Z"
    }
   },
   "outputs": [],
   "source": [
    "model_cfg = getattr(flow_ssl, args.flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:49.238916Z",
     "start_time": "2022-07-11T07:01:48.511974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model contains 87,859,080 parameters\n"
     ]
    }
   ],
   "source": [
    "if 'RealNVP' in args.flow:\n",
    "    net = model_cfg(in_channels=img_shape[0], \n",
    "                    init_zeros=args.init_zeros, \n",
    "                    mid_channels=args.num_mid_channels,\n",
    "                    num_scales=args.num_scales, \n",
    "                    st_type=args.st_type, \n",
    "                    use_batch_norm=not args.no_batchnorm)\n",
    "    \n",
    "elif args.flow == 'Glow':\n",
    "    net = model_cfg(image_shape=img_shape, \n",
    "                    mid_channels=args.num_mid_channels, \n",
    "                    num_scales=args.num_scales,\n",
    "                    num_coupling_layers_per_scale=args.num_coupling_layers_per_scale, \n",
    "                    num_layers=args.num_blocks,\n",
    "                    multi_scale=not args.no_multi_scale, \n",
    "                    st_type=args.st_type)\n",
    "\n",
    "print(f'Model contains {format(sum([p.numel() for p in net.parameters()]), \",d\")} parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:02:22.288355Z",
     "start_time": "2022-07-11T07:02:20.134143Z"
    }
   },
   "outputs": [],
   "source": [
    "D = int(np.prod(img_shape))\n",
    "\n",
    "prior = distributions.MultivariateNormal(torch.zeros(D).to(device), torch.eye(D).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:02:23.289699Z",
     "start_time": "2022-07-11T07:02:23.285900Z"
    }
   },
   "outputs": [],
   "source": [
    "class FlowLoss(nn.Module):\n",
    "    \"\"\"Get the NLL loss for a RealNVP model.\n",
    "\n",
    "    Args:\n",
    "        k (int or float): Number of discrete values in each input dimension.\n",
    "            E.g., `k` is 256 for natural images.\n",
    "\n",
    "    See Also:\n",
    "        Equation (3) in the RealNVP paper: https://arxiv.org/abs/1605.08803\n",
    "    \"\"\"\n",
    "    # Get 'Bits Per Dimension(BPD)' by subtracting \"np.log(self.k) * np.prod(z.size()[1:])\"\n",
    "    # ref : https://github.com/openai/glow/issues/43\n",
    "\n",
    "    def __init__(self, prior, k=256):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.prior = prior\n",
    "\n",
    "    def forward(self, z, sldj, y=None, mean=True):\n",
    "        z = z.reshape((z.shape[0], -1))\n",
    "        # prior_ll : negative value(log prob), -inf에서 0으로 가까워질 수록 data likelihood가 높아지는 것을 의미함\n",
    "        if y is not None:\n",
    "            prior_ll = self.prior.log_prob(z, y)\n",
    "        else:\n",
    "            prior_ll = self.prior.log_prob(z)\n",
    "            \n",
    "        corrected_prior_ll = prior_ll - np.log(self.k) * np.prod(z.size()[1:]) \n",
    "\n",
    "        ll = corrected_prior_ll + sldj\n",
    "        nll = -ll.mean() if mean else -ll  # nll : positive value(), inf에서 0으로 가까워 질수록 data likelihood가 높아지는 것을 의미함\n",
    "\n",
    "        return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:02:23.997125Z",
     "start_time": "2022-07-11T07:02:23.995098Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = FlowLoss(prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:02:24.336477Z",
     "start_time": "2022-07-11T07:02:24.328421Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'RealNVP' in args.flow:\n",
    "    # We need this to make sure that weight decay is only applied to g -- norm parameter in Weight Normalization\n",
    "    # RealNVP paper: https://arxiv.org/abs/1605.08803 \"3.7 Batch Normalization\"\n",
    "    # RealNVP use ResNet with Batch Normalization and Weight Normalization\n",
    "    param_groups = utils.get_param_groups(net, args.weight_decay, norm_suffix='weight_g')\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(param_groups, lr=args.lr)\n",
    "    else:\n",
    "        optimizer = optim.RMSprop(param_groups, lr=args.lr)\n",
    "\n",
    "elif args.flow == 'Glow':\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.RMSprop(net.parameters(), lr=args.lr, weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:02:52.987565Z",
     "start_time": "2022-07-11T07:02:52.984827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(param_groups) : 2\n",
      "param_groups[0].keys : dict_keys(['name', 'params', 'weight_decay', 'lr', 'betas', 'eps', 'amsgrad'])\n",
      "param_groups[1].keys : dict_keys(['name', 'params', 'lr', 'betas', 'eps', 'weight_decay', 'amsgrad'])\n"
     ]
    }
   ],
   "source": [
    "print(f'len(param_groups) : {len(param_groups)}')\n",
    "print(f'param_groups[0].keys : {param_groups[0].keys()}')\n",
    "print(f'param_groups[1].keys : {param_groups[1].keys()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:06:46.742082Z",
     "start_time": "2022-07-11T07:06:46.733962Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch, net, trainloader, device, optimizer, loss_fn, \n",
    "         max_grad_norm, negative_val=-1e5, num_samples=10, log_freq=100):\n",
    "\n",
    "    print(f'\\nEPOCH : {epoch}')\n",
    "    \n",
    "    net.train()\n",
    "    loss_meter = utils.AverageMeter()\n",
    "    pooler = MedianPool2d(7, padding=3)\n",
    "    \n",
    "    iter_count, batch_count = 0, 0\n",
    "    with tqdm(total=len(trainloader.dataset)) as progress_bar:\n",
    "        for x, _ in trainloader:\n",
    "\n",
    "            bs = x.shape[0]\n",
    "            iter_count+=1\n",
    "            batch_count+=bs\n",
    "            \n",
    "            x = x.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            z = net(x)\n",
    "            sldj = net.logdet()\n",
    "            \n",
    "            # NLL, positive value, inf -> 0으로 갈 수록 density estim better\n",
    "            # NLL Loss for IN (positive value), inf -> 0으로 갈수록 better(LL maximization)\n",
    "            loss = loss_fn(z, sldj=sldj, mean=False)\n",
    "            \n",
    "            loss.mean().backward()\n",
    "            utils.clip_grad_norm(optimizer, max_grad_norm)\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            # Log\n",
    "            loss_meter.update(loss.mean().item(), bs)\n",
    "            progress_bar.set_postfix(\n",
    "                bpd=utils.bits_per_dim(x, loss_meter.avg))\n",
    "            progress_bar.update(bs)\n",
    "\n",
    "            if iter_count % log_freq == 0 or batch_count == len(trainloader.dataset):\n",
    "                if use_wandb:\n",
    "                    wandb.log({'epoch' : epoch,\n",
    "                               'train | loss' : loss_meter.avg, \n",
    "                               'train | bpd' : utils.bits_per_dim(x, loss_meter.avg),\n",
    "                              })\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:08:10.511099Z",
     "start_time": "2022-07-11T07:08:10.506877Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(epoch, net, testloader, device, loss_fn, mode='in'):\n",
    "    net.eval()\n",
    "    loss_meter = utils.AverageMeter()\n",
    "    loss_list = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(testloader.dataset)) as progress_bar:\n",
    "            for x, _ in testloader:\n",
    "                x = x.to(device)\n",
    "                z = net(x)\n",
    "                sldj = net.logdet()\n",
    "                losses = loss_fn(z, sldj=sldj, mean=False)  \n",
    "                loss_list.extend([loss.item() for loss in losses])\n",
    "                \n",
    "                loss = losses.mean()   # loss =: NLL (positive value)\n",
    "                loss_meter.update(loss.item(), x.size(0))\n",
    "                \n",
    "                progress_bar.set_postfix(loss=loss_meter.avg,\n",
    "                                         bpd=utils.bits_per_dim(x, loss_meter.avg))\n",
    "                progress_bar.update(x.size(0))\n",
    "\n",
    "    likelihoods = -torch.from_numpy(np.array(loss_list)).float()  # -NLL (negative value)\n",
    "    \n",
    "    if use_wandb:\n",
    "        wandb.log({'epoch' : epoch,\n",
    "                   f'test|loss_{mode}' : loss_meter.avg,\n",
    "                   f'test|bpd_{mode}' : utils.bits_per_dim(x, loss_meter.avg),\n",
    "                   f'test|likelihoods_{mode}' : likelihoods})\n",
    "    \n",
    "    return likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training / test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:09:45.081148Z",
     "start_time": "2022-07-11T07:09:34.310071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 864/50000 [00:10<10:08, 80.71it/s, bpd=5.78]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-fa13bcf5b97f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     train(epoch, net, trainloader, device, optimizer, loss_fn, \n\u001b[0m\u001b[1;32m     12\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           negative_val=args.negative_val)\n",
      "\u001b[0;32m<ipython-input-21-3dd917f6cc4c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, net, trainloader, device, optimizer, loss_fn, max_grad_norm, negative_val, num_samples, log_freq)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0msldj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/desktop/0.study/AD/flows_ood_share/flow_ssl/realnvp/realnvp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/desktop/0.study/AD/flows_ood_share/flow_ssl/invertible/parts.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst_off\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/desktop/0.study/AD/flows_ood_share/flow_ssl/realnvp/coupling_layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, sldj, reverse)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mexp_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Scale factor has NaN entries'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mx_change\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_change\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mexp_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "net.to(device)\n",
    "seed_everything(0)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch + args.num_epochs + 1):\n",
    "    \n",
    "    if args.lr_anneal:\n",
    "        lr = schedule(args, epoch)\n",
    "        utils.adjust_learning_rate(optimizer, lr)\n",
    "        \n",
    "    train(epoch, net, trainloader, device, optimizer, loss_fn, \n",
    "          args.max_grad_norm, num_samples=args.num_samples, \n",
    "          negative_val=args.negative_val)\n",
    "    \n",
    "    test_ll = test(epoch, net, testloader, device, loss_fn, mode='in')  # LL (Not NLL)\n",
    "    test_ll_percentile = get_percentile(test_ll)  # 하위 5%의 loss 값 추출(높은 OOD에 해당하는 loss 값)\n",
    "    test_ll = test_ll.cpu().detach().numpy()\n",
    "\n",
    "    if args.ood_dataset:\n",
    "        ood_ll = test(epoch, net, ood_testloader, device, loss_fn, mode='ood')  # LL (Not NLL)\n",
    "        ood_ll_percentile = get_percentile(ood_ll)\n",
    "        ood_ll = ood_ll.cpu().detach().numpy()\n",
    "        \n",
    "        # AUC-ROC\n",
    "        n_ood, n_test = len(ood_ll), len(test_ll)\n",
    "        lls = np.hstack([ood_ll, test_ll])\n",
    "        targets = np.ones((n_ood + n_test,), dtype=int)\n",
    "        targets[:n_ood] = 0\n",
    "        score = roc_auc_score(targets, lls)\n",
    "        if use_wandb:\n",
    "            wandb.log({'ood/roc_auc': score})\n",
    "        \n",
    "\n",
    "    # plotting likelihood hists\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    sns.distplot(test_ll[test_ll > test_ll_percentile], label='test')  # 너무 예외적으로 낮게 뽑힌 Loss는 제외\n",
    "    if args.ood_dataset:\n",
    "        sns.distplot(ood_ll[ood_ll > ood_ll_percentile], label='OOD')\n",
    "    plt.legend()\n",
    "    fig.canvas.draw()\n",
    "    hist_img = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
    "    hist_img = torch.tensor(hist_img.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
    "    os.makedirs(os.path.join(args.ckptdir,f'LL_histogram'), exist_ok=True)\n",
    "    plt.savefig(os.path.join(args.ckptdir,f'LL_histogram/{epoch}.png'))\n",
    "    if use_wandb:\n",
    "        wandb.log({f\"LL_histogram\" : [wandb.Image(os.path.join(args.ckptdir,f'LL_histogram/{epoch}.png'))]})\n",
    "\n",
    "    # Save checkpoint\n",
    "    if (epoch % args.save_freq == 0):\n",
    "        print('Saving...')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'lls': lls,\n",
    "            'targets' : targets,\n",
    "            'ood/roc_auc' : score,\n",
    "        }\n",
    "        os.makedirs(args.ckptdir, exist_ok=True)\n",
    "        torch.save(state, os.path.join(args.ckptdir, str(epoch)+'.pt'))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomcrop\n",
    "- [Reference - torchvision official doc](https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:09:45.091275Z",
     "start_time": "2022-07-11T07:06:48.572Z"
    }
   },
   "outputs": [],
   "source": [
    "# sphinx_gallery_thumbnail_path = \"../../gallery/assets/transforms_thumbnail.png\"\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "orig_img = Image.open(Path('assets') / 'astronaut.jpg')\n",
    "# if you change the seed, make sure that the randomly-applied transforms\n",
    "# properly show that the image can be both transformed and *not* transformed!\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def plot(imgs, with_orig=True, row_title=None, **imshow_kwargs):\n",
    "    if not isinstance(imgs[0], list):\n",
    "        # Make a 2d grid even if there's just 1 row\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0]) + with_orig\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        row = [orig_img] + row if with_orig else row\n",
    "        for col_idx, img in enumerate(row):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if with_orig:\n",
    "        axs[0, 0].set(title='Original image')\n",
    "        axs[0, 0].title.set_size(8)\n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:50.467512Z",
     "start_time": "2022-07-11T07:01:43.350Z"
    }
   },
   "outputs": [],
   "source": [
    "print(orig_img.size)\n",
    "orig_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:50.468171Z",
     "start_time": "2022-07-11T07:01:43.351Z"
    }
   },
   "outputs": [],
   "source": [
    "cropper = T.RandomCrop(size=(256, 256), padding=4)\n",
    "crops = [cropper(orig_img) for _ in range(4)]\n",
    "plot(crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:50.468730Z",
     "start_time": "2022-07-11T07:01:43.352Z"
    }
   },
   "outputs": [],
   "source": [
    "cropper = T.RandomCrop(size=(256, 256), padding=200)\n",
    "crops = [cropper(orig_img) for _ in range(4)]\n",
    "plot(crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:50.469311Z",
     "start_time": "2022-07-11T07:01:43.353Z"
    }
   },
   "outputs": [],
   "source": [
    "cropper = T.RandomCrop(size=(256, 256), padding=100)\n",
    "crops = [cropper(orig_img) for _ in range(4)]\n",
    "plot(crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:50.469774Z",
     "start_time": "2022-07-11T07:01:43.354Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cropper = T.RandomCrop(size=(128, 128), padding=4)\n",
    "crops = [cropper(orig_img) for _ in range(4)]\n",
    "plot(crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:50.470283Z",
     "start_time": "2022-07-11T07:01:43.355Z"
    }
   },
   "outputs": [],
   "source": [
    "cropper = T.RandomCrop(size=(128, 128))\n",
    "crops = [cropper(orig_img) for _ in range(4)]\n",
    "plot(crops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T07:01:50.470845Z",
     "start_time": "2022-07-11T07:01:43.356Z"
    }
   },
   "outputs": [],
   "source": [
    "prior = distributions.MultivariateNormal(torch.zeros(2).to(device),\n",
    "                                         torch.eye(2).to(device))\n",
    "\n",
    "prior_examples = prior.sample(sample_shape=[5_000])\n",
    "exmp_df = pd.DataFrame({'x':prior_examples[:,0].to('cpu'), 'y':prior_examples[:,1].to('cpu')})\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.scatterplot(x=exmp_df['x'], y=exmp_df['y'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "172px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
