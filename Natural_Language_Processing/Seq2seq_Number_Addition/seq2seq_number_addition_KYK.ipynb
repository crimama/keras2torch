{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db19632-7e0d-4eca-ae12-99ef181d5511",
   "metadata": {},
   "source": [
    "# Sequence to sequence learning for performing number addition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc7722d-ed10-485e-b169-230c878a19b3",
   "metadata": {},
   "source": [
    "[Original Keras Code](https://keras.io/examples/nlp/addition_rnn/)\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Author**: Yookyung Kho\n",
    "\n",
    "**Date presented**: 2022/03/21, DSBA keras2torch Study\n",
    "\n",
    "**Task description**: multi-class classification, seq2seq, Training a model to learn to add two numbers, provided as strings.\n",
    "\n",
    "**References**:\n",
    "\n",
    "- [갓기현 NMT seq2seq](https://github.com/kh-kim/simple-nmt/blob/master/simple_nmt/models/seq2seq.py)\n",
    "- [wikidocs seq2seq](https://wikidocs.net/24996)\n",
    "- [torch seq2seq](https://codlingual.tistory.com/91)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Example**:\n",
    "\n",
    "- Input: `\"61+535\"`\n",
    "- Output: `\"596\"`\n",
    "\n",
    "**Results**:\n",
    "\n",
    "For two digits (reversed):\n",
    "\n",
    "- One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "\n",
    "**Three digits (reversed):**\n",
    "\n",
    "- One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "\n",
    "Four digits (reversed):\n",
    "\n",
    "- One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "\n",
    "Five digits (reversed):\n",
    "\n",
    "- One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83528104-67c5-4771-8593-3d64a249945a",
   "metadata": {},
   "source": [
    "<img src=\"seq2seq.png\" width=\"900\" height=\"900\">\n",
    "\n",
    "> **구현 상 원본 keras 코드를 따라가느라 애써 무시했지만 여전히 찝찝한 부분**\n",
    ">\n",
    "> (1) 임베딩을 아예 하지 않고 one-hot 벡터를 바로 LSTM input으로 보냄 (즉, 임베딩을 통해 lstm input을 continous하게 만들지 않고 discrete한 형태로 바로 투입)\n",
    "> * _이래도 keras 구현체에서는 성능 잘 나온다고 함(torch 버전에서는 학습 잘 안됨..ㅠ)_\n",
    ">\n",
    "> (2) 패딩 처리가 모호함\n",
    "> * _아예 안해줌. keras 코드에서도 따로 padding 옵션 걸어줘야 하는 것으로 알고 있는데, 이 구현체에서는 단순히 0번 index만 1로 채워진 원핫 벡터가 패딩 역할을 수행할 것이라고만 언급함_\n",
    "> \n",
    "> (3) Decoding 시에 <EOS> token을 반환하면 stop하는 등의 후처리가 전혀 없음. output 숫자가 최대 4자릿수라 output length를 4로 고정하고 <PAD> 자체를 예측하도록 함\n",
    "> * _input, output length의 범위가 고정되어 있어서(각각 7, 4) 디코딩 시에 <BOS>는 필요해도 <EOS>는 굳이 필요하지 않을 듯 하나..._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3016f5-782d-4eff-8fac-614474306d4b",
   "metadata": {},
   "source": [
    "## 1. Import & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad44fec8-feed-45ab-be20-d2573f409b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import wandb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d815edc-8515-4e7a-9258-b96d6fbe11a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset.\n",
    "SEED_NUM = 602\n",
    "DATA_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "NUM_LAYERS = 1\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "PAD_IDX = 0\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a81cf8-ab29-452a-aea1-118ede0ab4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "seed_everything(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462a90ce-c903-4252-bf0b-1427ce7528d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c4d91-49f9-4e0c-b57b-9d6e811717a2",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d0aec7-514d-4617-a395-d058845aa917",
   "metadata": {},
   "source": [
    "### 2.1. Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6685c059-32e8-4a2c-a060-5afb3653d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data_size, max_num_len):\n",
    "    ### max_num_len = 3\n",
    "    max_ques_len = max_num_len + 1 + max_num_len #7\n",
    "    questions = []\n",
    "    answers = []\n",
    "    seen = set()\n",
    "    \n",
    "    while len(questions) < data_size:\n",
    "\n",
    "        # #(0) 숫자를 반복 샘플링해서 합치는 lambda 함수 f\n",
    "        f = lambda: int(\n",
    "            \"\".join(\n",
    "                np.random.choice(list(\"0123456789\")) # 숫자 랜덤 샘플링 (0~9)\n",
    "                for i in range(np.random.randint(1, max_num_len + 1)) # i번 반복 (i: 1~3 중 랜덤)\n",
    "            )\n",
    "        )\n",
    "        a, b = f(), f()\n",
    "        ## ex) a=7, b=15\n",
    "\n",
    "        # Skip any addition questions we've already seen :수식 중복 방지\n",
    "        # Also skip any such that x+Y == Y+x (hence the sorting). :순서만 바뀐 동일 수식도 제외\n",
    "        key = tuple(sorted((a, b)))\n",
    "\n",
    "        # seen 집합에 중복 tuple 있을 경우 다음 iteration으로 넘어감 \n",
    "        if key in seen:\n",
    "            continue\n",
    "\n",
    "        seen.add(key)\n",
    "        ## ex) seen = {(7, 15), (35, 33), ...}\n",
    "        ## ex) 만약 a=15, b=7이 주어져도 sorted를 통해 (7,15)와 같이 오름차순으로 정렬되기 때문에 중복으로 인지\n",
    "\n",
    "        # 수식을 string 형태로 생성\n",
    "        ques = f\"{a}+{b}\"\n",
    "        # Pad the data with spaces such that it is always MAXLEN.\n",
    "        query = ques + \" \" * (max_ques_len - len(ques)) # 수식 문자열에 공백 추가\n",
    "\n",
    "        ans = str(a + b) # 정답 계산\n",
    "        # Answers can be of maximum size max_num_len(3) + 1.\n",
    "        ans += \" \" * (max_num_len + 1 - len(ans)) # 정답 문자열에 공백 추가\n",
    "        \n",
    "        questions.append(query)\n",
    "        answers.append(ans)\n",
    "        \n",
    "    print(\"Total questions:\", len(questions))\n",
    "    \n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99cfefa8-1fc6-46b6-9343-5795116ec03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'a', 'p', 'p', 'y']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(0) lambda 함수(익명함수): 결과를 return 키워드 없이 자동으로 반환 / 함수 이름 x\n",
    "\n",
    "a = lambda x: list(x)\n",
    "a(\"happy\") # -> ['h', 'a', 'p', 'p', 'y']\n",
    "\n",
    "b = lambda: list(\"happy\")\n",
    "b() # -> ['h', 'a', 'p', 'p', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75033efa-59ab-46ef-89df-4dba04559889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions: 50000\n",
      "questions: ['88+26  ', '9+2    ', '0+2    ', '4+1    ', '80+59  ']\n",
      "answers: ['114 ', '11  ', '2   ', '5   ', '139 ']\n"
     ]
    }
   ],
   "source": [
    "questions, answers = generate_data(DATA_SIZE, 3)\n",
    "\n",
    "print(f\"questions: {questions[:5]}\\nanswers: {answers[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c4ec4-7671-4e5e-9c33-dd2361252162",
   "metadata": {},
   "source": [
    "### 2.2. Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0be77f32-a2cc-462c-9d5b-bab5e4d7d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(question, answer):\n",
    "    # Shuffle\n",
    "    ques = np.array(question)\n",
    "    ans = np.array(answer)\n",
    "    \n",
    "    indices = np.arange(ques.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    question = ques[indices]\n",
    "    answer = ans[indices]\n",
    "    \n",
    "    # Train(9)/Valid(1) Split\n",
    "    split_at = len(question) - len(question) // 10\n",
    "    (x_train, x_val) = question[:split_at], question[split_at:] # question\n",
    "    (y_train, y_val) = answer[:split_at], answer[split_at:] # answer\n",
    "\n",
    "    print(f\"Training Data: {len(x_train)}\")\n",
    "    print(f\"Validation Data: {len(x_val)}\")\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a35f31d6-f79d-40e5-9663-de1a01b644fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 45000\n",
      "Validation Data: 5000\n",
      "['127+16 ' '74+369 ' '438+673' '64+313 ' '52+869 ']\n",
      "['143 ' '443 ' '1111' '377 ' '921 ']\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = split_data(questions, answers)\n",
    "\n",
    "print(x_train[:5])\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0b2edc-1e9a-4645-ab88-bf569b0d4e96",
   "metadata": {},
   "source": [
    "### 2.3. Create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4639d4fd-eaae-4d0b-bf36-d84f3a8739d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class to be used in a PyTorch DataLoader to create batches.\n",
    "    \"\"\"\n",
    "    def __init__(self, questions, answers):\n",
    "        self.questions = questions #np array 1d\n",
    "        self.answers = answers #np array 1d\n",
    "        \n",
    "        # All the numbers, plus sign and space for padding.\n",
    "        chars = \"0123456789+ \"\n",
    "        self.chars = sorted(set(chars)) # (1) 숫자, 기호, 공백 분절 후 리스트로 저장\n",
    "        self.chars.append('\\t') # BOS token('\\t') 추가\n",
    "        \n",
    "        # (2) one-hot 인코딩을 위해 character에 고유 인덱스 부여한 dictionary 생성\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "        \n",
    "        self.max_len = 7\n",
    "        self.max_len_output = 4\n",
    "        self.num_class = len(self.char_indices) # 13\n",
    "        \n",
    "        \n",
    "    def txt_to_tensor(self, char_txt: str, is_reverse: bool, is_idx: bool):\n",
    "        \"\"\"\n",
    "        char string => continuous tensor(idx) or one-hot tensor 반환\n",
    "        (idx tensor: loss 계산용)\n",
    "        \"\"\"\n",
    "        \n",
    "        if is_reverse:\n",
    "            # question reverse: 공백이 앞으로 가게끔 수식 문자열 후처리 (Note the space used for padding.)\n",
    "            ## 디코더에서 인코더의 관련 부분까지 경로를 단축하여 long term dependencies 문제를 완화 목적\n",
    "            ## (Sutskever et al., 2014) 입력 값을 뒤집지 않은 경우에 비해 약간의 개선 효과\n",
    "            ## ex) '12+345  ' => '  543+21'\n",
    "            char_txt = char_txt[::-1] # 문자열 거꾸로\n",
    "            \n",
    "        char_tensor = torch.zeros(len(char_txt)).long() #long() 안해주면 0값이 float로 지정되어 아래 인덱싱에서 에러 발생\n",
    "        \n",
    "        for i in range(len(char_txt)):\n",
    "            char_tensor[i]=self.char_indices[char_txt[i]] #index로 채워서 continuous tensor로 만들어줌\n",
    "            \n",
    "        char_onehot = nn.functional.one_hot(char_tensor, num_classes=self.num_class) # LongTensor(dtype=int32)\n",
    "        char_onehot = char_onehot.to(torch.float32) ## torch gpu 연산 시 longtensor 처리할 수 없기 때문에 FloatTensor(dtype=float32)로 변환\n",
    "        # |char_onehot| = (max_len(7),num_class(13)) or (max_len(4),num_class(13))\n",
    "        \n",
    "        if is_idx:\n",
    "            return char_tensor, char_onehot\n",
    "        else:\n",
    "            return char_onehot\n",
    "            \n",
    "\n",
    "    def tensor_to_txt(self, char_tensor):\n",
    "        \"\"\"\n",
    "        1d idx(continuous) tensor => char string \n",
    "        \"\"\"\n",
    "        char_array = char_tensor.cpu().detach().numpy()\n",
    "        \n",
    "        num_string = \"\"\n",
    "        for i in range(len(char_array)):\n",
    "            num_string += self.indices_char[char_array[i]]\n",
    "            \n",
    "        return num_string\n",
    "                \n",
    "        \n",
    "    def __getitem__(self, idx: int):\n",
    "        ques = self.questions[idx]\n",
    "        ans = self.answers[idx]\n",
    "        \n",
    "        ques_onehot = self.txt_to_tensor(ques, is_reverse=True, is_idx=False)\n",
    "        ans_idx, ans_onehot = self.txt_to_tensor(ans, is_reverse=False, is_idx=True)\n",
    "        \n",
    "        batch = {'question_onehot': ques_onehot, #2d tensor\n",
    "                 'answer_idx_tensor': ans_idx, #1d tensor\n",
    "                 'answer_onehot': ans_onehot} #2d tensor\n",
    "\n",
    "        return batch\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self.num_class\n",
    "    \n",
    "    @property\n",
    "    def max_ques_len(self):\n",
    "        return self.max_len #7\n",
    "    \n",
    "    @property\n",
    "    def max_ans_len(self):\n",
    "        return self.max_len_output #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c754697-668b-4ef9-aae2-3eb2a614d95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', '+', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) 숫자, 기호, 공백 분절 후 리스트로 저장\n",
    "chars = \"0123456789+ \"\n",
    "chars = sorted(set(chars))\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7b596-1318-4af4-bf5e-da0e5eafe926",
   "metadata": {},
   "source": [
    "공백이 포함되는 이유:\n",
    "\n",
    "- 주어지는 수식이 `'  73+37'`와 같이 MAXLEN(7)에 맞게 앞부분은 공백으로 채워지기 때문\n",
    "- 공백은 후에 padding 역할 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3055e72b-7425-4ea4-b6ef-763fe6fabaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '+': 1,\n",
       " '0': 2,\n",
       " '1': 3,\n",
       " '2': 4,\n",
       " '3': 5,\n",
       " '4': 6,\n",
       " '5': 7,\n",
       " '6': 8,\n",
       " '7': 9,\n",
       " '8': 10,\n",
       " '9': 11}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) one-hot 인코딩을 위해 character에 고유 인덱스 부여한 dictionary 생성\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "char_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5166336d-3e27-4a1f-8ee8-579a1cd4605c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: '+',\n",
       " 2: '0',\n",
       " 3: '1',\n",
       " 4: '2',\n",
       " 5: '3',\n",
       " 6: '4',\n",
       " 7: '5',\n",
       " 8: '6',\n",
       " 9: '7',\n",
       " 10: '8',\n",
       " 11: '9'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaa8eb56-cc89-4fa6-9e58-3670ec21736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices['\\t'] = 12\n",
    "indices_char[12] = '\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b598d387-a98e-4f10-8d09-db34d99e50a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '+': 1,\n",
       " '0': 2,\n",
       " '1': 3,\n",
       " '2': 4,\n",
       " '3': 5,\n",
       " '4': 6,\n",
       " '5': 7,\n",
       " '6': 8,\n",
       " '7': 9,\n",
       " '8': 10,\n",
       " '9': 11,\n",
       " '\\t': 12}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af4fc6c8-2527-44b0-a9f7-caa9282e5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "valid_dataset = CustomDataset(x_val, y_val)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 64)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf736eda-2f74-452f-83e8-8d149348a9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_onehot': tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]]]),\n",
       " 'answer_idx_tensor': tensor([[3, 6, 5, 0],\n",
       "         [6, 6, 5, 0]]),\n",
       " 'answer_onehot': tensor([[[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size 2 예시\n",
    "batch_ex = next(iter(train_dataloader))\n",
    "batch_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e19d3f3e-4444-49f1-90e7-204c6ac9f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_onehot shape: torch.Size([2, 7, 13])\n",
      "answer_idx_tensor: torch.Size([2, 4])\n",
      "answer_onehot: torch.Size([2, 4, 13])\n"
     ]
    }
   ],
   "source": [
    "# batch size 2 예시\n",
    "print(f\"question_onehot shape: {batch_ex['question_onehot'].shape}\")\n",
    "print(f\"answer_idx_tensor: {batch_ex['answer_idx_tensor'].shape}\")\n",
    "print(f\"answer_onehot: {batch_ex['answer_onehot'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460b8984-0b78-4b25-9420-9f19580caefc",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592292fa-8c83-4049-b67e-cb14a97fd23a",
   "metadata": {},
   "source": [
    "Lstm seq2seq model\n",
    "\n",
    "- **Lstm Encoder**\n",
    "    - hid dim=128\n",
    "    - num_layers에 따라 stacking 가능(실험은 keras 구현체와 같이 1 layer로 진행)\n",
    "\n",
    "- **Lstm Decoder**\n",
    "    - hid dim=128\n",
    "    - num_layers에 따라 stacking 가능(실험은 keras 구현체와 같이 1 layer로 진행)\n",
    "    - training: teacher forcing\n",
    "    - inference: greedy decoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c79129e-9743-4999-82ae-cdada65d5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lstm_Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, num_layers):\n",
    "        super().__init__()\n",
    "        #self.embedding = nn.Embedding(input_dim, emb_dim) #(batch_size, seq_len, emb_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hid_dim, num_layers) # dropout=dropout\n",
    "        \n",
    "    def forward(self, input_batch):\n",
    "        # input_batch: (batch_size, seq_len, input_dim)\n",
    "        ## input은 원핫 형태이므로 input_dim=13\n",
    "        \n",
    "        input_batch = torch.transpose(input_batch, 0, 1)\n",
    "        # (seq_len, batch_size, input_dim) ### batch_first=False\n",
    "        \n",
    "        lstm_outs, (h_t, h_c) = self.lstm(input_batch)\n",
    "    \n",
    "        # lstm_outs: (seq_len, batch_size, hid dim * n directions)\n",
    "        ## packed sequence which is the output of lstm at every step\n",
    "        ## bidirectional RNN의 경우 : n_directions=2\n",
    "        # h_t: (num layers * n directions, batch_size, hid dim)\n",
    "        # c_t: (num layers * n directions, batch_size, hid dim)\n",
    "        \n",
    "        return h_t, h_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35439308-5b7c-49ec-ac2d-9bcb70e17cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lstm_Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, num_layers):\n",
    "        super().__init__()\n",
    "        ### input_dim=output_dim = 13\n",
    "        self.lstm = nn.LSTM(input_dim, hid_dim, num_layers) # dropout=dropout\n",
    "        self.linear = nn.Linear(hid_dim, input_dim) # output_dim = input_dim(13)\n",
    "        \n",
    "    def forward(self, input_one, h_t, h_c):\n",
    "        \"\"\"one time step\"\"\"\n",
    "        # input_one: (batch_size, 1, input_dim)\n",
    "        ## 원핫벡터이므로 input_dim=13\n",
    "        \n",
    "        input_one = torch.transpose(input_one, 0, 1) # (1, batch_size, input_dim(13)) ### batch_first=False\n",
    "        dec_lstm_outs, (h_t, h_c) = self.lstm(input_one, (h_t, h_c))\n",
    "        # dec_lstm_outs: (1, batch_size, hid dim * n directions)\n",
    "        # h_t: (num layers * n directions, batch_size, hid dim)\n",
    "        \n",
    "        output = dec_lstm_outs.squeeze(0) # (batch size, hid dim * n directions)\n",
    "        pred = self.linear(output) # (batch size, output dim) # output_dim = input_dim(13)\n",
    "        \n",
    "        return pred, h_t, h_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3eb1278-dfed-4156-a328-4b9a2fd541a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7554, -1.8747, -1.5196]],\n",
      "\n",
      "        [[ 1.7377,  1.0045,  0.0661]]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = torch.randn(2,1,3).to(device)\n",
    "print(ex)\n",
    "torch.argmax(ex, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "448b02cf-896c-453a-a057-b27f30ae2539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.one_hot(torch.argmax(ex, dim=-1), num_classes=dec_input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7de5b2f3-56b2-4359-9028-b82878e46ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_input_dim = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "202ea008-06f3-45ae-87cc-95a80758241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### teacher forcing 제거 다시 실험\n",
    "class Lstm_seq2seq(nn.Module):\n",
    "    def __init__(self, enc_input_dim, dec_input_dim, hid_dim, num_layers, device):\n",
    "        ### encoder decoder hid_dim, num_layers 같아야함!!!!\n",
    "        super().__init__()\n",
    "        self.encoder = Lstm_Encoder(enc_input_dim, hid_dim, num_layers)\n",
    "        self.decoder = Lstm_Decoder(dec_input_dim, hid_dim, num_layers)\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, enc_input_batch, dec_input_batch):\n",
    "        ### |enc_input_batch| = (batch_size, enc_seq_len(7), input_dim(13))\n",
    "        ### |dec_input_batch| = (batch_size, seq_len(4), input_dim(13))\n",
    "        \n",
    "        # 1. encode\n",
    "        enc_h_t, enc_h_c = self.encoder(enc_input_batch)\n",
    "        \n",
    "        # 2. decode(teacher forcing)\n",
    "        batch_size, seq_len, dec_input_dim = dec_input_batch.shape\n",
    "        \n",
    "        input1 = torch.zeros(batch_size, 1, dec_input_dim).to(self.device)\n",
    "        input1[:,:,12] = 1 #bos 직접 생성\n",
    "        \n",
    "        preds = []\n",
    "        for t in range(seq_len): ###\n",
    "            #print(t, input1) ##### error!!!\n",
    "            pred, dec_h_t, dec_h_c = self.decoder(input1, enc_h_t, enc_h_c)\n",
    "            # |pred| = (batch size, output dim)\n",
    "            \n",
    "            ## *방법1: pred tensor concat\n",
    "            pred = pred.unsqueeze(1) # (batch_size, 1, output dim) # seq용 차원을 중간에 하나 추가해야 뒤에서 concat할 수 있음\n",
    "            preds += [pred] #append와 같음\n",
    "            \n",
    "            input1 = nn.functional.one_hot(torch.argmax(pred, dim=-1), num_classes=dec_input_dim)\n",
    "            input1 = input1.to(torch.float32)\n",
    "            \n",
    "            ## *방법2: zero tensor 채워넣기\n",
    "            #outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "            #outputs[t] = pred\n",
    "            \n",
    "            # teacher forcing\n",
    "            #input1 = dec_input_batch[:, t, :].unsqueeze(1)\n",
    "            # |input1| = (batch_size, 1, dec out dim)\n",
    "            \n",
    "        outputs = torch.cat(preds, dim=1)\n",
    "        # |outputs| = (batch_size, length(4), output dim)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    # inference 용도(valid, test)\n",
    "    def encode(self, enc_input_batch):\n",
    "        ### |enc_input_batch| = (batch_size(1), enc_seq_len(7), input_dim(13))\n",
    "        enc_h_t, enc_h_c = self.encoder(enc_input_batch)\n",
    "        return enc_h_t, enc_h_c\n",
    "    \n",
    "    def decode(self, dec_input, enc_h_t, enc_h_c):\n",
    "        # |dec_input| = (1, current seq len, input_dim(13))!!! or (batch size, current seq len, input_dim(13))\n",
    "        #맨 마지막 time step 벡터 가져오기\n",
    "        real_input = dec_input[:,-1,:].unsqueeze(1) # |real_input| = (batch_size(1),1,input_dim(13))\n",
    "        pred, _, _ = self.decoder(real_input, enc_h_t, enc_h_c) #dec_h_t, dec_h_c는 필요 없으므로 날려~\n",
    "        # |pred| = (batch size, output dim)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df2a8d25-317e-442a-89b9-251c40926d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Lstm_seq2seq                             --\n",
       "├─Lstm_Encoder: 1-1                      --\n",
       "│    └─LSTM: 2-1                         73,216\n",
       "├─Lstm_Decoder: 1-2                      --\n",
       "│    └─LSTM: 2-2                         73,216\n",
       "│    └─Linear: 2-3                       1,677\n",
       "=================================================================\n",
       "Total params: 148,109\n",
       "Trainable params: 148,109\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Lstm_seq2seq(enc_input_dim=13, dec_input_dim=13, hid_dim=128, num_layers=NUM_LAYERS, device=device).to(device)\n",
    "\n",
    "#summary(model, ((1,7,13), (1,4,13)))\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eded9691-4afa-4b69-b93d-bc6b3397960b",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f56666cd-e872-49a9-bcc8-cc89b7d5426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CE Loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#criterion = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "# Optimizer : Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a2d8390-3249-4967-bdea-038e32f2d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        ques_onehot = batch['question_onehot'].to(device)\n",
    "        ans_idx = batch['answer_idx_tensor'].to(device) # |ans_idx| = (batch_size, length(4))\n",
    "        ans_onehot = batch['answer_onehot'].to(device)\n",
    "        \n",
    "        outputs = model(ques_onehot, ans_onehot) # |outputs| = (batch_size, length(4), output dim)\n",
    "        \n",
    "        # Calculate loss, Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # loss 계산을 위해\n",
    "        ## outputs(3d tensor)를 2d로 변환\n",
    "        outputs_2d = outputs.contiguous().view(-1, outputs.size(-1)) # |outputs_2d| = (batch_size*length(4), output dim)\n",
    "        ## ans_idx(정답 2d tensor)를 1d로 변환\n",
    "        ans_idx_1d = ans_idx.contiguous().view(-1) # |ans_idx_1d| = (batch_size*length(5))\n",
    "        \n",
    "        loss = criterion(outputs_2d, ans_idx_1d)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses += loss.item()\n",
    "        \n",
    "    return losses / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61c9375e-afcf-4fbf-b2b5-06eeba1f620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        ques_onehot = batch['question_onehot'].to(device)\n",
    "        ans_idx = batch['answer_idx_tensor'].to(device) # |ans_idx| = (batch_size, length(4))\n",
    "        ans_onehot = batch['answer_onehot'].to(device)\n",
    "        \n",
    "        outputs = model(ques_onehot, ans_onehot) # |outputs| = (batch_size, length(4), output dim)\n",
    "        \n",
    "        # loss 계산을 위해\n",
    "        ## outputs(3d tensor)를 2d로 변환\n",
    "        outputs_2d = outputs.contiguous().view(-1, outputs.size(-1)) # |outputs_2d| = (batch_size*length(4), output dim)\n",
    "        ## ans_idx(정답 2d tensor)를 1d로 변환\n",
    "        ans_idx_1d = ans_idx.contiguous().view(-1) # |ans_idx_1d| = (batch_size*length(4))\n",
    "        \n",
    "        loss = criterion(outputs_2d, ans_idx_1d)\n",
    "        \n",
    "        losses += loss.item()\n",
    "    \n",
    "    return losses / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a96e7467-5bae-41aa-94fd-8d7875c8209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### inference 용 greedy decode 함수\n",
    "def greedy_decode(ques_txt, dataset, model, device):\n",
    "    ques_onehot = dataset.txt_to_tensor(ques_txt, is_reverse=True, is_idx=False)\n",
    "    \n",
    "    input_ques = ques_onehot.unsqueeze(0).to(device)\n",
    "    \n",
    "    enc_h_t, enc_h_c = model.encode(input_ques)\n",
    "    \n",
    "    dec_input_dim = dataset.num_class\n",
    "    input1 = torch.zeros(1, 1, dec_input_dim).to(device) # dataset.num_class = 13\n",
    "    input1[:,:,dec_input_dim-1] = 1 #bos 직접 생성 #12\n",
    "    \n",
    "    for t in range(dataset.max_ans_len):\n",
    "        pred = model.decode(input1, enc_h_t, enc_h_c)\n",
    "        pred = pred.unsqueeze(0) # (batch_size(1), 1, output dim)\n",
    "        input1 = torch.cat((input1,pred), dim=1) # |input1| = (batch_size(1), +1, output dim) #반복마다 seq 추가\n",
    "    \n",
    "    result = input1[:,1:,:].squeeze(0) # (seq len, output dim) = (4,13)\n",
    "    result_idx_tensor = torch.argmax(result, dim=-1) # (seq len,)\n",
    "    \n",
    "    pred_ans = dataset.tensor_to_txt(result_idx_tensor) # string\n",
    "    \n",
    "    return pred_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86564758-caff-48b9-a5d7-a49a02ce01ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 1.304, Val loss: 1.264, Epoch time = 7.333s\n",
      ">>> Q: 96+463  => T: 559   ☒: 5   \n",
      ">>> Q: 1+96    => T: 97    ☒: 96  \n",
      ">>> Q: 558+3   => T: 561   ☒: 5   \n",
      ">>> Q: 939+388 => T: 1327  ☒: 16  \n",
      ">>> Q: 43+210  => T: 253   ☒: 2   \n",
      ">>> Q: 138+540 => T: 678   ☒: 6   \n",
      ">>> Q: 48+988  => T: 1036  ☒: 16  \n",
      "Epoch: 10, Train loss: 0.748, Val loss: 0.719, Epoch time = 6.479s\n",
      ">>> Q: 858+174 => T: 1032  ☒: 1421\n",
      ">>> Q: 65+842  => T: 907   ☒: 96  \n",
      ">>> Q: 328+5   => T: 333   ☒: 3   \n",
      ">>> Q: 601+991 => T: 1592  ☒: 1602\n",
      ">>> Q: 566+22  => T: 588   ☒: 5   \n",
      ">>> Q: 382+787 => T: 1169  ☒: 17 1\n",
      ">>> Q: 561+775 => T: 1336  ☒: 17  \n",
      "Epoch: 15, Train loss: 0.411, Val loss: 0.439, Epoch time = 7.199s\n",
      ">>> Q: 10+720  => T: 730   ☒: 76  \n",
      ">>> Q: 12+325  => T: 337   ☒: 3   \n",
      ">>> Q: 788+902 => T: 1690  ☒: 1611\n",
      ">>> Q: 119+422 => T: 541   ☒: 5511\n",
      ">>> Q: 541+38  => T: 579   ☒: 5   \n",
      ">>> Q: 606+58  => T: 664   ☒: 60  \n",
      ">>> Q: 64+467  => T: 531   ☒: 5   \n",
      "Epoch: 20, Train loss: 0.289, Val loss: 0.320, Epoch time = 6.289s\n",
      ">>> Q: 89+63   => T: 152   ☒: 10  \n",
      ">>> Q: 974+298 => T: 1272  ☒: 15 1\n",
      ">>> Q: 7+759   => T: 766   ☒: 75  \n",
      ">>> Q: 69+78   => T: 147   ☒: 1  1\n",
      ">>> Q: 6+577   => T: 583   ☒: 55 1\n",
      ">>> Q: 305+263 => T: 568   ☒: 5 1 \n",
      ">>> Q: 500+867 => T: 1367  ☒: 16 1\n",
      "Epoch: 25, Train loss: 0.234, Val loss: 0.276, Epoch time = 6.565s\n",
      ">>> Q: 521+85  => T: 606   ☒: 6   \n",
      ">>> Q: 225+327 => T: 552   ☒: 5 11\n",
      ">>> Q: 143+22  => T: 165   ☒: 181 \n",
      ">>> Q: 18+612  => T: 630   ☒: 66  \n",
      ">>> Q: 263+6   => T: 269   ☒: 2   \n",
      ">>> Q: 546+60  => T: 606   ☒: 6   \n",
      ">>> Q: 849+67  => T: 916   ☒: 9   \n",
      "Epoch: 30, Train loss: 0.209, Val loss: 0.249, Epoch time = 6.756s\n",
      ">>> Q: 821+93  => T: 914   ☒: 96  \n",
      ">>> Q: 24+24   => T: 48    ☒: 4   \n",
      ">>> Q: 734+27  => T: 761   ☒: 71 1\n",
      ">>> Q: 16+311  => T: 327   ☒: 3   \n",
      ">>> Q: 727+39  => T: 766   ☒: 719 \n",
      ">>> Q: 78+244  => T: 322   ☒: 3   \n",
      ">>> Q: 593+27  => T: 620   ☒: 6   \n",
      "Epoch: 35, Train loss: 0.194, Val loss: 0.231, Epoch time = 7.249s\n",
      ">>> Q: 0+945   => T: 945   ☒: 9   \n",
      ">>> Q: 34+16   => T: 50    ☒: 5   \n",
      ">>> Q: 7+622   => T: 629   ☒: 6   \n",
      ">>> Q: 6+846   => T: 852   ☒: 8   \n",
      ">>> Q: 754+10  => T: 764   ☒: 716 \n",
      ">>> Q: 475+969 => T: 1444  ☒: 1635\n",
      ">>> Q: 283+78  => T: 361   ☒: 3   \n",
      "Epoch: 40, Train loss: 0.183, Val loss: 0.216, Epoch time = 6.238s\n",
      ">>> Q: 438+755 => T: 1193  ☒: 16 4\n",
      ">>> Q: 420+395 => T: 815   ☒: 8810\n",
      ">>> Q: 34+647  => T: 681   ☒: 6   \n",
      ">>> Q: 257+608 => T: 865   ☒: 883 \n",
      ">>> Q: 967+432 => T: 1399  ☒: 1981\n",
      ">>> Q: 819+6   => T: 825   ☒: 8   \n",
      ">>> Q: 81+52   => T: 133   ☒: 105 \n",
      "Epoch: 45, Train loss: 0.178, Val loss: 0.215, Epoch time = 6.621s\n",
      ">>> Q: 645+84  => T: 729   ☒: 7   \n",
      ">>> Q: 565+93  => T: 658   ☒: 6   \n",
      ">>> Q: 309+813 => T: 1122  ☒: 16 1\n",
      ">>> Q: 0+683   => T: 683   ☒: 6 6 \n",
      ">>> Q: 348+474 => T: 822   ☒: 88  \n",
      ">>> Q: 822+336 => T: 1158  ☒: 16  \n",
      ">>> Q: 935+3   => T: 938   ☒: 97  \n",
      "Epoch: 50, Train loss: 0.171, Val loss: 0.212, Epoch time = 6.280s\n",
      ">>> Q: 692+154 => T: 846   ☒: 8  4\n",
      ">>> Q: 177+833 => T: 1010  ☒: 1  0\n",
      ">>> Q: 33+901  => T: 934   ☒: 961 \n",
      ">>> Q: 65+77   => T: 142   ☒: 17  \n",
      ">>> Q: 5+822   => T: 827   ☒: 8   \n",
      ">>> Q: 16+6    => T: 22    ☒: 2   \n",
      ">>> Q: 248+1   => T: 249   ☒: 2   \n",
      "Epoch: 55, Train loss: 0.167, Val loss: 0.197, Epoch time = 6.906s\n",
      ">>> Q: 288+8   => T: 296   ☒: 25  \n",
      ">>> Q: 57+696  => T: 753   ☒: 79 3\n",
      ">>> Q: 238+33  => T: 271   ☒: 26  \n",
      ">>> Q: 957+28  => T: 985   ☒: 97  \n",
      ">>> Q: 978+422 => T: 1400  ☒: 1  2\n",
      ">>> Q: 11+595  => T: 606   ☒: 6   \n",
      ">>> Q: 793+44  => T: 837   ☒: 8   \n",
      "Epoch: 60, Train loss: 0.166, Val loss: 0.192, Epoch time = 6.577s\n",
      ">>> Q: 77+776  => T: 853   ☒: 88  \n",
      ">>> Q: 740+555 => T: 1295  ☒: 16 7\n",
      ">>> Q: 733+362 => T: 1095  ☒: 16  \n",
      ">>> Q: 375+21  => T: 396   ☒: 3  4\n",
      ">>> Q: 430+625 => T: 1055  ☒: 16 1\n",
      ">>> Q: 257+608 => T: 865   ☒: 8 4 \n",
      ">>> Q: 69+723  => T: 792   ☒: 786 \n",
      "Epoch: 65, Train loss: 0.162, Val loss: 0.186, Epoch time = 7.098s\n",
      ">>> Q: 845+208 => T: 1053  ☒: 1635\n",
      ">>> Q: 56+975  => T: 1031  ☒: 160 \n",
      ">>> Q: 17+286  => T: 303   ☒: 3  3\n",
      ">>> Q: 88+299  => T: 387   ☒: 36  \n",
      ">>> Q: 51+152  => T: 203   ☒: 2   \n",
      ">>> Q: 659+789 => T: 1448  ☒: 17  \n",
      ">>> Q: 477+50  => T: 527   ☒: 5 19\n",
      "Epoch: 70, Train loss: 0.160, Val loss: 0.187, Epoch time = 6.059s\n",
      ">>> Q: 809+77  => T: 886   ☒: 8   \n",
      ">>> Q: 918+436 => T: 1354  ☒: 165 \n",
      ">>> Q: 543+1   => T: 544   ☒: 5 5 \n",
      ">>> Q: 70+642  => T: 712   ☒: 78  \n",
      ">>> Q: 19+780  => T: 799   ☒: 789 \n",
      ">>> Q: 695+112 => T: 807   ☒: 8294\n",
      ">>> Q: 13+450  => T: 463   ☒: 4   \n",
      "Epoch: 75, Train loss: 0.158, Val loss: 0.185, Epoch time = 7.025s\n",
      ">>> Q: 67+559  => T: 626   ☒: 67  \n",
      ">>> Q: 73+799  => T: 872   ☒: 8886\n",
      ">>> Q: 136+242 => T: 378   ☒: 3  2\n",
      ">>> Q: 595+19  => T: 614   ☒: 6  4\n",
      ">>> Q: 55+47   => T: 102   ☒: 1   \n",
      ">>> Q: 790+3   => T: 793   ☒: 700 \n",
      ">>> Q: 6+552   => T: 558   ☒: 5   \n",
      "Epoch: 80, Train loss: 0.158, Val loss: 0.179, Epoch time = 6.525s\n",
      ">>> Q: 299+11  => T: 310   ☒: 3  4\n",
      ">>> Q: 726+7   => T: 733   ☒: 7   \n",
      ">>> Q: 554+87  => T: 641   ☒: 6   \n",
      ">>> Q: 29+84   => T: 113   ☒: 1651\n",
      ">>> Q: 463+669 => T: 1132  ☒: 165 \n",
      ">>> Q: 269+565 => T: 834   ☒: 88 0\n",
      ">>> Q: 286+102 => T: 388   ☒: 3 44\n",
      "Epoch: 85, Train loss: 0.155, Val loss: 0.179, Epoch time = 7.140s\n",
      ">>> Q: 605+70  => T: 675   ☒: 670 \n",
      ">>> Q: 437+52  => T: 489   ☒: 45  \n",
      ">>> Q: 153+652 => T: 805   ☒: 89 9\n",
      ">>> Q: 56+79   => T: 135   ☒: 10  \n",
      ">>> Q: 343+4   => T: 347   ☒: 3   \n",
      ">>> Q: 272+238 => T: 510   ☒: 55  \n",
      ">>> Q: 130+770 => T: 900   ☒: 9 08\n",
      "Epoch: 90, Train loss: 0.155, Val loss: 0.172, Epoch time = 6.835s\n",
      ">>> Q: 29+84   => T: 113   ☒: 165 \n",
      ">>> Q: 551+33  => T: 584   ☒: 5516\n",
      ">>> Q: 700+267 => T: 967   ☒: 9919\n",
      ">>> Q: 898+43  => T: 941   ☒: 96  \n",
      ">>> Q: 15+637  => T: 652   ☒: 6 26\n",
      ">>> Q: 61+884  => T: 945   ☒: 9716\n",
      ">>> Q: 23+702  => T: 725   ☒: 73  \n",
      "Epoch: 95, Train loss: 0.153, Val loss: 0.178, Epoch time = 6.908s\n",
      ">>> Q: 293+23  => T: 316   ☒: 3   \n",
      ">>> Q: 81+760  => T: 841   ☒: 88  \n",
      ">>> Q: 35+57   => T: 92    ☒: 9   \n",
      ">>> Q: 2+855   => T: 857   ☒: 8   \n",
      ">>> Q: 5+403   => T: 408   ☒: 49  \n",
      ">>> Q: 954+446 => T: 1400  ☒: 1  0\n",
      ">>> Q: 567+65  => T: 632   ☒: 6   \n",
      "Epoch: 100, Train loss: 0.152, Val loss: 0.174, Epoch time = 6.750s\n",
      ">>> Q: 74+613  => T: 687   ☒: 67  \n",
      ">>> Q: 48+997  => T: 1045  ☒: 1787\n",
      ">>> Q: 37+696  => T: 733   ☒: 7786\n",
      ">>> Q: 609+245 => T: 854   ☒: 88 3\n",
      ">>> Q: 245+73  => T: 318   ☒: 3   \n",
      ">>> Q: 650+0   => T: 650   ☒: 6   \n",
      ">>> Q: 793+6   => T: 799   ☒: 78 9\n"
     ]
    }
   ],
   "source": [
    "### teacher forcing x\n",
    "\n",
    "# Wandb Settings for logging\n",
    "# wandb.init(project=\"Seq2seq Number Addition\", name=f\"lstm {NUM_LAYERS} layer\", entity=\"yookyungkho\")\n",
    "        \n",
    "# wandb.config.update({\"epochs\": NUM_EPOCHS,\n",
    "#                      \"batch_size\": BATCH_SIZE,\n",
    "#                      \"learning_rate\" : LEARNING_RATE})\n",
    "        \n",
    "# wandb.watch(model, log=\"all\")\n",
    "\n",
    "# training start!\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    \n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, criterion, device)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate_epoch(model, valid_dataloader, criterion, device)\n",
    "    \n",
    "    # Add log in wandb page\n",
    "    # wandb.log({'train_loss': train_loss, 'val_loss': val_loss})\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    \n",
    "        for i in range(7):\n",
    "            idx = np.random.randint(0, len(x_val))\n",
    "            x_txt, y_txt = x_val[idx], y_val[idx]\n",
    "            y_pred = greedy_decode(x_txt, valid_dataset, model, device)\n",
    "            if y_txt == y_pred:\n",
    "                print(f\">>> Q: {x_txt} => T: {y_txt}  ☑: {y_pred}\")\n",
    "            else:\n",
    "                print(f\">>> Q: {x_txt} => T: {y_txt}  ☒: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87df1810-9a95-4d19-ade9-22bd30a94d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myookyungkho\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/yookyungkho/Seq2seq%20Number%20Addition/runs/fw8ol5q6\" target=\"_blank\">lstm 1 layer</a></strong> to <a href=\"https://wandb.ai/yookyungkho/Seq2seq%20Number%20Addition\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 1.445, Val loss: 1.389, Epoch time = 6.388s\n",
      ">>> Q: 96+463  => T: 559   ☒: 5   \n",
      ">>> Q: 1+96    => T: 97    ☒: 9   \n",
      ">>> Q: 558+3   => T: 561   ☒: 5   \n",
      ">>> Q: 939+388 => T: 1327  ☒: 13  \n",
      ">>> Q: 43+210  => T: 253   ☒: 2   \n",
      ">>> Q: 138+540 => T: 678   ☒: 63  \n",
      ">>> Q: 48+988  => T: 1036  ☒: 10  \n",
      "Epoch: 10, Train loss: 0.731, Val loss: 0.704, Epoch time = 6.758s\n",
      ">>> Q: 858+174 => T: 1032  ☒: 1441\n",
      ">>> Q: 65+842  => T: 907   ☒: 938 \n",
      ">>> Q: 328+5   => T: 333   ☒: 30 0\n",
      ">>> Q: 601+991 => T: 1592  ☒: 1382\n",
      ">>> Q: 566+22  => T: 588   ☒: 54  \n",
      ">>> Q: 382+787 => T: 1169  ☒: 1482\n",
      ">>> Q: 561+775 => T: 1336  ☒: 1441\n",
      "Epoch: 15, Train loss: 0.382, Val loss: 0.395, Epoch time = 6.219s\n",
      ">>> Q: 10+720  => T: 730   ☒: 740 \n",
      ">>> Q: 12+325  => T: 337   ☒: 3940\n",
      ">>> Q: 788+902 => T: 1690  ☒: 1380\n",
      ">>> Q: 119+422 => T: 541   ☒: 5040\n",
      ">>> Q: 541+38  => T: 579   ☒: 5404\n",
      ">>> Q: 606+58  => T: 664   ☒: 64  \n",
      ">>> Q: 64+467  => T: 531   ☒: 5438\n",
      "Epoch: 20, Train loss: 0.245, Val loss: 0.278, Epoch time = 6.443s\n",
      ">>> Q: 89+63   => T: 152   ☒: 1061\n",
      ">>> Q: 974+298 => T: 1272  ☒: 1062\n",
      ">>> Q: 7+759   => T: 766   ☒: 7   \n",
      ">>> Q: 69+78   => T: 147   ☒: 1060\n",
      ">>> Q: 6+577   => T: 583   ☒: 5040\n",
      ">>> Q: 305+263 => T: 568   ☒: 50 0\n",
      ">>> Q: 500+867 => T: 1367  ☒: 1471\n",
      "Epoch: 25, Train loss: 0.187, Val loss: 0.225, Epoch time = 6.351s\n",
      ">>> Q: 521+85  => T: 606   ☒: 6382\n",
      ">>> Q: 225+327 => T: 552   ☒: 5051\n",
      ">>> Q: 143+22  => T: 165   ☒: 1849\n",
      ">>> Q: 18+612  => T: 630   ☒: 60  \n",
      ">>> Q: 263+6   => T: 269   ☒: 2044\n",
      ">>> Q: 546+60  => T: 606   ☒: 6380\n",
      ">>> Q: 849+67  => T: 916   ☒: 9442\n",
      "Epoch: 30, Train loss: 0.160, Val loss: 0.193, Epoch time = 6.499s\n",
      ">>> Q: 821+93  => T: 914   ☒: 9442\n",
      ">>> Q: 24+24   => T: 48    ☒: 40  \n",
      ">>> Q: 734+27  => T: 761   ☒: 7547\n",
      ">>> Q: 16+311  => T: 327   ☒: 3040\n",
      ">>> Q: 727+39  => T: 766   ☒: 75 1\n",
      ">>> Q: 78+244  => T: 322   ☒: 3026\n",
      ">>> Q: 593+27  => T: 620   ☒: 6440\n",
      "Epoch: 35, Train loss: 0.146, Val loss: 0.183, Epoch time = 6.627s\n",
      ">>> Q: 0+945   => T: 945   ☒: 9384\n",
      ">>> Q: 34+16   => T: 50    ☒: 5420\n",
      ">>> Q: 7+622   => T: 629   ☒: 60  \n",
      ">>> Q: 6+846   => T: 852   ☒: 8448\n",
      ">>> Q: 754+10  => T: 764   ☒: 7582\n",
      ">>> Q: 475+969 => T: 1444  ☒: 1062\n",
      ">>> Q: 283+78  => T: 361   ☒: 3049\n",
      "Epoch: 40, Train loss: 0.135, Val loss: 0.168, Epoch time = 6.068s\n",
      ">>> Q: 438+755 => T: 1193  ☒: 1762\n",
      ">>> Q: 420+395 => T: 815   ☒: 8694\n",
      ">>> Q: 34+647  => T: 681   ☒: 6586\n",
      ">>> Q: 257+608 => T: 865   ☒: 8665\n",
      ">>> Q: 967+432 => T: 1399  ☒: 1760\n",
      ">>> Q: 819+6   => T: 825   ☒: 85  \n",
      ">>> Q: 81+52   => T: 133   ☒: 100 \n",
      "Epoch: 45, Train loss: 0.129, Val loss: 0.160, Epoch time = 6.201s\n",
      ">>> Q: 645+84  => T: 729   ☒: 7062\n",
      ">>> Q: 565+93  => T: 658   ☒: 6020\n",
      ">>> Q: 309+813 => T: 1122  ☒: 1062\n",
      ">>> Q: 0+683   => T: 683   ☒: 6470\n",
      ">>> Q: 348+474 => T: 822   ☒: 8628\n",
      ">>> Q: 822+336 => T: 1158  ☒: 1760\n",
      ">>> Q: 935+3   => T: 938   ☒: 934 \n",
      "Epoch: 50, Train loss: 0.127, Val loss: 0.157, Epoch time = 6.684s\n",
      ">>> Q: 692+154 => T: 846   ☒: 8395\n",
      ">>> Q: 177+833 => T: 1010  ☒: 1642\n",
      ">>> Q: 33+901  => T: 934   ☒: 9403\n",
      ">>> Q: 65+77   => T: 142   ☒: 1040\n",
      ">>> Q: 5+822   => T: 827   ☒: 8496\n",
      ">>> Q: 16+6    => T: 22    ☒: 2760\n",
      ">>> Q: 248+1   => T: 249   ☒: 2740\n",
      "Epoch: 55, Train loss: 0.124, Val loss: 0.145, Epoch time = 6.491s\n",
      ">>> Q: 288+8   => T: 296   ☒: 2647\n",
      ">>> Q: 57+696  => T: 753   ☒: 7546\n",
      ">>> Q: 238+33  => T: 271   ☒: 20 2\n",
      ">>> Q: 957+28  => T: 985   ☒: 9496\n",
      ">>> Q: 978+422 => T: 1400  ☒: 1172\n",
      ">>> Q: 11+595  => T: 606   ☒: 6666\n",
      ">>> Q: 793+44  => T: 837   ☒: 8592\n",
      "Epoch: 60, Train loss: 0.122, Val loss: 0.147, Epoch time = 5.884s\n",
      ">>> Q: 77+776  => T: 853   ☒: 8367\n",
      ">>> Q: 740+555 => T: 1295  ☒: 1760\n",
      ">>> Q: 733+362 => T: 1095  ☒: 1460\n",
      ">>> Q: 375+21  => T: 396   ☒: 306 \n",
      ">>> Q: 430+625 => T: 1055  ☒: 1442\n",
      ">>> Q: 257+608 => T: 865   ☒: 8607\n",
      ">>> Q: 69+723  => T: 792   ☒: 7 9 \n",
      "Epoch: 65, Train loss: 0.118, Val loss: 0.142, Epoch time = 6.740s\n",
      ">>> Q: 845+208 => T: 1053  ☒: 1062\n",
      ">>> Q: 56+975  => T: 1031  ☒: 1059\n",
      ">>> Q: 17+286  => T: 303   ☒: 37  \n",
      ">>> Q: 88+299  => T: 387   ☒: 3640\n",
      ">>> Q: 51+152  => T: 203   ☒: 2742\n",
      ">>> Q: 659+789 => T: 1448  ☒: 1760\n",
      ">>> Q: 477+50  => T: 527   ☒: 5470\n",
      "Epoch: 70, Train loss: 0.118, Val loss: 0.139, Epoch time = 5.992s\n",
      ">>> Q: 809+77  => T: 886   ☒: 8641\n",
      ">>> Q: 918+436 => T: 1354  ☒: 1755\n",
      ">>> Q: 543+1   => T: 544   ☒: 5063\n",
      ">>> Q: 70+642  => T: 712   ☒: 7 82\n",
      ">>> Q: 19+780  => T: 799   ☒: 707 \n",
      ">>> Q: 695+112 => T: 807   ☒: 8172\n",
      ">>> Q: 13+450  => T: 463   ☒: 4070\n",
      "Epoch: 75, Train loss: 0.117, Val loss: 0.133, Epoch time = 6.764s\n",
      ">>> Q: 67+559  => T: 626   ☒: 6542\n",
      ">>> Q: 73+799  => T: 872   ☒: 8469\n",
      ">>> Q: 136+242 => T: 378   ☒: 3960\n",
      ">>> Q: 595+19  => T: 614   ☒: 6405\n",
      ">>> Q: 55+47   => T: 102   ☒: 16  \n",
      ">>> Q: 790+3   => T: 793   ☒: 7080\n",
      ">>> Q: 6+552   => T: 558   ☒: 5944\n",
      "Epoch: 80, Train loss: 0.113, Val loss: 0.133, Epoch time = 6.384s\n",
      ">>> Q: 299+11  => T: 310   ☒: 3209\n",
      ">>> Q: 726+7   => T: 733   ☒: 7446\n",
      ">>> Q: 554+87  => T: 641   ☒: 6060\n",
      ">>> Q: 29+84   => T: 113   ☒: 17 4\n",
      ">>> Q: 463+669 => T: 1132  ☒: 176 \n",
      ">>> Q: 269+565 => T: 834   ☒: 8642\n",
      ">>> Q: 286+102 => T: 388   ☒: 3206\n",
      "Epoch: 85, Train loss: 0.112, Val loss: 0.131, Epoch time = 6.555s\n",
      ">>> Q: 605+70  => T: 675   ☒: 6486\n",
      ">>> Q: 437+52  => T: 489   ☒: 4682\n",
      ">>> Q: 153+652 => T: 805   ☒: 8672\n",
      ">>> Q: 56+79   => T: 135   ☒: 1065\n",
      ">>> Q: 343+4   => T: 347   ☒: 30  \n",
      ">>> Q: 272+238 => T: 510   ☒: 5467\n",
      ">>> Q: 130+770 => T: 900   ☒: 9492\n",
      "Epoch: 90, Train loss: 0.112, Val loss: 0.135, Epoch time = 6.796s\n",
      ">>> Q: 29+84   => T: 113   ☒: 1769\n",
      ">>> Q: 551+33  => T: 584   ☒: 5530\n",
      ">>> Q: 700+267 => T: 967   ☒: 9606\n",
      ">>> Q: 898+43  => T: 941   ☒: 9669\n",
      ">>> Q: 15+637  => T: 652   ☒: 657 \n",
      ">>> Q: 61+884  => T: 945   ☒: 9442\n",
      ">>> Q: 23+702  => T: 725   ☒: 7402\n",
      "Epoch: 95, Train loss: 0.112, Val loss: 0.137, Epoch time = 6.481s\n",
      ">>> Q: 293+23  => T: 316   ☒: 3060\n",
      ">>> Q: 81+760  => T: 841   ☒: 8692\n",
      ">>> Q: 35+57   => T: 92    ☒: 9446\n",
      ">>> Q: 2+855   => T: 857   ☒: 8446\n",
      ">>> Q: 5+403   => T: 408   ☒: 4646\n",
      ">>> Q: 954+446 => T: 1400  ☒: 1692\n",
      ">>> Q: 567+65  => T: 632   ☒: 6020\n",
      "Epoch: 100, Train loss: 0.111, Val loss: 0.129, Epoch time = 6.527s\n",
      ">>> Q: 74+613  => T: 687   ☒: 6571\n",
      ">>> Q: 48+997  => T: 1045  ☒: 1099\n",
      ">>> Q: 37+696  => T: 733   ☒: 7442\n",
      ">>> Q: 609+245 => T: 854   ☒: 8506\n",
      ">>> Q: 245+73  => T: 318   ☒: 30  \n",
      ">>> Q: 650+0   => T: 650   ☒: 6696\n",
      ">>> Q: 793+6   => T: 799   ☒: 7 70\n"
     ]
    }
   ],
   "source": [
    "### teacher forcing o\n",
    "\n",
    "# Wandb Settings for logging\n",
    "# wandb.init(project=\"Seq2seq Number Addition\", name=f\"lstm {NUM_LAYERS} layer\", entity=\"yookyungkho\")\n",
    "        \n",
    "# wandb.config.update({\"epochs\": NUM_EPOCHS,\n",
    "#                      \"batch_size\": BATCH_SIZE,\n",
    "#                      \"learning_rate\" : LEARNING_RATE})\n",
    "        \n",
    "# wandb.watch(model, log=\"all\")\n",
    "\n",
    "# training start!\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    \n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, criterion, device)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate_epoch(model, valid_dataloader, criterion, device)\n",
    "    \n",
    "    # Add log in wandb page\n",
    "    wandb.log({'train_loss': train_loss, 'val_loss': val_loss})\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    \n",
    "        for i in range(7):\n",
    "            idx = np.random.randint(0, len(x_val))\n",
    "            x_txt, y_txt = x_val[idx], y_val[idx]\n",
    "            y_pred = greedy_decode(x_txt, valid_dataset, model, device)\n",
    "            if y_txt == y_pred:\n",
    "                print(f\">>> Q: {x_txt} => T: {y_txt}  ☑: {y_pred}\")\n",
    "            else:\n",
    "                print(f\">>> Q: {x_txt} => T: {y_txt}  ☒: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4326baa-c347-4e2f-a3c9-550bbab399b1",
   "metadata": {},
   "source": [
    "- keras 결과와는 다르게 대부분 4자리 숫자로 정답 반환, loss 잘 안떨어짐\n",
    "- EOS token 추가했을 때 결과 더 심각\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
