{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e660871",
   "metadata": {},
   "source": [
    "# Spanish-to-English translation with a sequence-to-sequence Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad6c2e7",
   "metadata": {},
   "source": [
    "- Source Language: Spanish (`¿A dónde conduce este camino?`)\n",
    "- Target Language: English (`Where does this road lead?`)\n",
    "\n",
    "\n",
    "[Original Keras Code](https://keras.io/examples/nlp/neural_machine_translation_with_transformer/) : **English-to-Spanish** translation with a sequence-to-sequence Transformer \n",
    "\n",
    "\n",
    "결과 해석의 용이성을 위해 번역 순서 바꿔서(Spanish-to-English) 구현\n",
    "\n",
    "</br>\n",
    "\n",
    "\n",
    "reference\n",
    "- https://pytorch.org/text/0.11.0/vocab.html#build-vocab-from-iterator\n",
    "- https://github.com/hwk0702/keras2torch/blob/main/Natural_Language_Processing/Extra/TorchText_introduction_KJS.ipynb\n",
    "- https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d072d9",
   "metadata": {},
   "source": [
    "## 0. Setup, Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada1ea2",
   "metadata": {},
   "source": [
    "torchtext, spacy, en_core_web_sm, es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchtext\n",
    "#!pip install -U spacy\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4792776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext.utils import download_from_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9ffc23",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0356afd",
   "metadata": {},
   "source": [
    "## 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65db1733",
   "metadata": {},
   "source": [
    "anki : https://www.manythings.org/anki/\n",
    "\n",
    "- 영어-제2외국어 sentence pair dataset\n",
    "\n",
    "- English + TAB + The Other Language + TAB + Attribution\n",
    "\n",
    "> This work isn't easy.\tこの仕事は簡単じゃない。\tCC-BY 2.0 (France) Attribution: tatoeba.org #3737550 (CK) & #7977622 (Ninja)\n",
    "\n",
    "> Those are sunflowers.\tそれはひまわりです。\tCC-BY 2.0 (France) Attribution: tatoeba.org #441940 (CK) & #205407 (arnab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f65336",
   "metadata": {},
   "source": [
    "### 1.1. data 저장 폴더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a8654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = 'data/' # 현재 디렉토리에 data 폴더 추가\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1404e2",
   "metadata": {},
   "source": [
    "### 1.2. data 압축파일 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c1aaa8",
   "metadata": {},
   "source": [
    "`torchtext.utils`의 `download_from_url`를 활용하여 anki 사이트에서 spa-eng.zip 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d732c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2.64M/2.64M [00:00<00:00, 11.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/yookyung/codes/data/spa-eng.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.utils import download_from_url\n",
    "\n",
    "url = 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
    "download_from_url(url, path=None, root=path, overwrite=False, hash_value=None, hash_type='sha256')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f67e9e",
   "metadata": {},
   "source": [
    "### 1.3. 압축 해제 with zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a52cdd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_file=zipfile.ZipFile(path + \"spa-eng.zip\") #path는 위에서 정의한 'data/'\n",
    "zip_file.extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a5a103",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e594e01e",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe8eaa",
   "metadata": {},
   "source": [
    "### 2.1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4b57bb",
   "metadata": {},
   "source": [
    "txt 파일 한 줄씩 읽어들이면서 스페인어-영어 pair로 구성된 튜플 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8b0ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "path = 'data/'\n",
    "pth = path+ \"spa-eng/spa.txt\"\n",
    "text_file = pathlib.Path(pth)\n",
    "\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    eng, spa = line.split(\"\\t\")\n",
    "    text_pairs.append((spa, eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54870efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Anoche tuve un sueño extraño.', 'I had a strange dream last night.')\n",
      "('Tal vez venga.', 'Perhaps he will come.')\n",
      "('Esta estufa quema aceite.', 'This stove burns oil.')\n",
      "('Tom no quiere estar cerca de Mary.', \"Tom doesn't want to be around Mary.\")\n",
      "('Oí a alguien decir mi nombre desde detrás.', 'I heard someone call my name from behind.')\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8225d197",
   "metadata": {},
   "source": [
    "tuple 형태로 sentence pair(스페인어, 영어) 구성되어있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93340f5e",
   "metadata": {},
   "source": [
    "### 2.2. train, valid, test set으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "048d9d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118964 total pairs\n",
      "83276 training pairs\n",
      "17844 validation pairs\n",
      "17844 test pairs\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
    "\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ddaefc-d44d-4f2c-9066-fb8b19f612a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('La primavera está a la vuelta de la esquina.',\n",
       "  'Spring is just around the corner.'),\n",
       " ('Ellos no son mis verdaderos padres.', \"They aren't my real parents.\"),\n",
       " ('Él no tenía más opción que huir.', 'He had no choice but to run away.'),\n",
       " ('Por favor, esperarme.', 'Please wait for me.'),\n",
       " ('No tengo ni idea de lo que está pasando.',\n",
       "  \"I've no idea what's happening.\"),\n",
       " ('No tengo tanto dinero como crees.',\n",
       "  \"I don't have as much money as you think.\"),\n",
       " ('Él mantuvo su promesa.', 'He kept his promise.'),\n",
       " ('La Guerra de 1812 había comenzado.', 'The War of 1812 had begun.'),\n",
       " ('Alguien llamó a la puerta.', 'Somebody knocked at the door.'),\n",
       " ('Quiero más dinero.', 'I want more money.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pairs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca05d629",
   "metadata": {},
   "source": [
    "### 2.3. 토크나이저 정의 및 단어사전 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8416d79a",
   "metadata": {},
   "source": [
    "`torchtext` 최신 버전: `get_tokenizer`, `build_vocab_from_iterator`\n",
    "- 이전 버전(field 정의해서 순차적으로 전처리)과의 차이는 [github](https://github.com/hwk0702/keras2torch/blob/main/Natural_Language_Processing/Extra/TorchText_introduction_KJS.ipynb) 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf2bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U spacy\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73b8a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "src_lang = 'spanish'\n",
    "trg_lang = 'english'\n",
    "\n",
    "tokenizer = {}\n",
    "\n",
    "tokenizer[src_lang] = get_tokenizer('spacy', language = \"es_core_news_sm\") #spanish #español\n",
    "tokenizer[trg_lang] = get_tokenizer('spacy', language = \"en_core_web_sm\") # english\n",
    "\n",
    "### spacy tokenizer 참고: https://yujuwon.tistory.com/entry/spaCy-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4f386",
   "metadata": {},
   "source": [
    "`build_vocab_from_iterator`: Build a Vocab from an iterator.\n",
    "\n",
    "\n",
    "```python\n",
    "torchtext.vocab.build_vocab_from_iterator(iterator: Iterable, min_freq: int = 1, specials: Optional[List[str]] = None, special_first: bool = True) \n",
    "```\n",
    "\n",
    "- iterator – Iterator used to build Vocab. Must yield list or iterator of tokens.\n",
    "\n",
    "- min_freq – The minimum frequency needed to include a token in the vocabulary.\n",
    "\n",
    "- specials – Special symbols to add. The order of supplied tokens will be preserved.\n",
    "\n",
    "- special_first – Indicates whether to insert symbols at the beginning or at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6ee99f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List\n",
    "\n",
    "# generator: 이터레이터를 생성해주는 함수\n",
    "### 이터레이터는 클래스에 __iter__, __next__ 또는 __getitem__ 메서드를 구현해야 하지만\n",
    "### 제너레이터는 함수 안에서 yield라는 키워드만 사용하면 끝\n",
    "### 대용량 반복을 수행해야할 때, 메모리를 더욱 효율적으로 사용하기 위한 도구\n",
    "##### 참고1: https://dojang.io/mod/page/view.php?id=2412\n",
    "##### 참고2: https://nirsa.tistory.com/118\n",
    "\n",
    "def yield_tokens(data: Iterable , language: str) -> List[str]:\n",
    "    \n",
    "    language_index = {src_lang: 0, trg_lang: 1}\n",
    "    \n",
    "    for sample in data:\n",
    "        yield tokenizer[language](sample[language_index[language]])\n",
    "        \n",
    "        # (스페인어, 영어) sentence pair\n",
    "        # ex) spn_tokenizer(sample1[0]) # 첫번째 문장 pair의 스페인어 문장 토크나이징\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eff1b995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object yield_tokens at 0x7fefe036f040>\n",
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "result = yield_tokens(train_pairs[:5], 'spanish')\n",
    "print(result)\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2daf3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Esto', 'es', 'totalmente', 'inaceptable', '.']\n",
      "['Pensé', 'que', 'eras', 'un', 'hombre', 'de', 'honor', '.']\n",
      "['Somos', 'las', 'primeras', 'en', 'llegar', '.']\n",
      "['No', 'nos', 'desanimemos', 'ahora', '.']\n",
      "['Dependemos', 'de', 'usted', '.']\n"
     ]
    }
   ],
   "source": [
    "# 토큰화 결과 출력\n",
    "for i in range(5):\n",
    "    print(next(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9f457b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "vocab_dict = {} #단어 집합\n",
    "\n",
    "special_tokens = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "\n",
    "for language in [src_lang, trg_lang]:\n",
    "    # 언어 별로 torchtext의 Vocab(단어 집합) 객체 생성\n",
    "    vocab_dict[language] = build_vocab_from_iterator(yield_tokens(train_pairs, language), min_freq=2, specials=special_tokens, special_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ade7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNK_IDX를 기본 인덱스로 설정 -> 토큰을 찾지 못하는 경우에 반환\n",
    "## 설정안해두면 RuntimeError 발생\n",
    "\n",
    "for language in [src_lang, trg_lang]:\n",
    "    vocab_dict[language].set_default_index(UNK_IDX) #unk_idx=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c9246a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spanish': Vocab(), 'english': Vocab()}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc20b52",
   "metadata": {},
   "source": [
    "언어별로 Vocab 인스턴스 생성 (참고: https://pytorch.org/text/0.11.0/vocab.html#torchtext.vocab.Vocab )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7bb38c5-cefa-47c2-96f3-0bb9264f1fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<unk>', 0),\n",
       " ('<pad>', 1),\n",
       " ('<bos>', 2),\n",
       " ('<eos>', 3),\n",
       " ('.', 4),\n",
       " ('I', 5),\n",
       " ('to', 6),\n",
       " ('the', 7),\n",
       " ('Tom', 8),\n",
       " ('you', 9),\n",
       " ('a', 10),\n",
       " ('?', 11),\n",
       " ('is', 12),\n",
       " (\"n't\", 13),\n",
       " (\"'s\", 14),\n",
       " ('in', 15)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_vocab = vocab_dict[trg_lang].get_stoi()\n",
    "\n",
    "sorted(eng_vocab.items(), key = lambda x: x[1])[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cbdb05",
   "metadata": {},
   "source": [
    "\\<unk>, \\<pad> 등의 special 토큰들이 상단에 위치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07495e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spanish 단어 집합 크기: 13640\n",
      "english 단어 집합 크기: 8319\n"
     ]
    }
   ],
   "source": [
    "print(f\"spanish 단어 집합 크기: {len(vocab_dict[src_lang])}\")\n",
    "print(f\"english 단어 집합 크기: {len(vocab_dict[trg_lang])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7b9ee",
   "metadata": {},
   "source": [
    "스페인어가 더 많은 이유: 어미, 단어 형태의 다양성(인칭, 격에 따라 다름)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8744bbe1",
   "metadata": {},
   "source": [
    "### 2.4. data -> tensor 변환 (Vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a31aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def txt_to_tensor(text, language):\n",
    "    tokens = tokenizer[language](text)\n",
    "    token_ids = vocab_dict[language](tokens)\n",
    "    return torch.cat((torch.tensor([BOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a2a23a",
   "metadata": {},
   "source": [
    "`collate_fn`: collate lists of samples into batches\n",
    "\n",
    "- custom collate_fn can be used to customize collation, e.g., padding sequential data to max length of a batch\n",
    "\n",
    "- 참고: https://pytorch.org/docs/stable/data.html#dataloader-collate-fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a4554cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DatoLoader에 쓰일 collate_fn 커스터마이징\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    src_batch, trg_batch = [],[]\n",
    "    \n",
    "    for src_sample, trg_sample in batch:\n",
    "        src_batch.append(txt_to_tensor(src_sample, src_lang))\n",
    "        trg_batch.append(txt_to_tensor(trg_sample, trg_lang))\n",
    "    \n",
    "    # padding\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX)\n",
    "    \n",
    "    src_batch = src_batch.transpose(0,1)\n",
    "    trg_batch = trg_batch.transpose(0,1)\n",
    "    \n",
    "    return src_batch, trg_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82b602fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "##collate_fn 참고: https://pytorch.org/docs/stable/data.html\n",
    "train_dataloader = DataLoader(train_pairs, batch_size = 128, collate_fn = custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36ee0a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[   2,  177,   15,  ...,    1,    1,    1],\n",
      "        [   2,  228,    6,  ...,    1,    1,    1],\n",
      "        [   2,  806,   38,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [   2,   17, 1963,  ...,    1,    1,    1],\n",
      "        [   2,    7,   53,  ...,    1,    1,    1],\n",
      "        [   2,  116,   15,  ...,    1,    1,    1]]), tensor([[  2,  59,  12,  ...,   1,   1,   1],\n",
      "        [  2,   5, 151,  ...,   1,   1,   1],\n",
      "        [  2,  40,  37,  ...,   1,   1,   1],\n",
      "        ...,\n",
      "        [  2,  18,  66,  ...,   1,   1,   1],\n",
      "        [  2,   8,  19,  ...,   1,   1,   1],\n",
      "        [  2,  59,  12,  ...,   1,   1,   1]]))\n",
      "torch.Size([128, 19])\n"
     ]
    }
   ],
   "source": [
    "batch_ex = next(iter(train_dataloader))\n",
    "print(batch_ex)\n",
    "print(batch_ex[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b488d0a3",
   "metadata": {},
   "source": [
    "(batch_size,sen_length), bos_idx=2, pad_idx=1\n",
    "\n",
    "pytorch는 단어 시퀀스를 정수 인덱스 시퀀스로 바꾸고 원-핫 벡터로 한번 더 바꾸고나서 임베딩 층의 입력으로 사용하는 것이 아니라, 단어를 정수 인덱스로만 바꾼채로 임베딩 층의 입력으로 사용해도 룩업 테이블 된 결과인 임베딩 벡터를 리턴 -> 원핫 인코딩 안해도 됨!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1060961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(batch_ex[0].shape[1])\n",
    "print(batch_ex[1].shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c9a673",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e64a17d",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eaf7bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3e1c18",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "\n",
    ":Encoder-Decoder로 구성된 seq2seq model\n",
    "\n",
    ":Architecture\n",
    "    \n",
    "![transformer](transformer.png)\n",
    "    \n",
    "- Input(source-spanish) Embedding + Positional Encoding\n",
    "- Encoder block\n",
    "    - **Multi-head Self-Attention**\n",
    "        - MSA 이전(input), 이후 차원 동일\n",
    "    - Residual Connection\n",
    "    - Layer Norm\n",
    "    \n",
    "    - **Position-wise FFN**\n",
    "        - head 별 mix up\n",
    "    - Residual Connection\n",
    "    - Layer Norm\n",
    "\n",
    "- Output(target-english) Embedding + Positional Encoding\n",
    "\n",
    "- Decoder block\n",
    "    - Encoder와 동일 + 몇가지 장치 추가\n",
    "    \n",
    "    - **Masked Multi-Head Self-Attention**\n",
    "        - 디코딩 시 미래 시점 참고 방지\n",
    "    - Residual Connection\n",
    "    - Layer Norm\n",
    "    \n",
    "    - **Encoder-Decoder Attention**\n",
    "        - Query: decoder output, Key&Value: encoder output\n",
    "    - Residual Connection\n",
    "    - Layer Norm\n",
    "    \n",
    "    - **Position-wise FFN**\n",
    "    - Residual Connection\n",
    "    - Layer Norm\n",
    "    \n",
    "\n",
    "\n",
    "> 다 구현해보고자 했으나... 시간 부족으로 nn.Transformer 활용.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c6f6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff4dde06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 14 15:44:39 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.00    Driver Version: 470.82.00    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| 31%   37C    P8    23W / 250W |    615MiB / 11016MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       989      G   /usr/lib/xorg/Xorg                 40MiB |\n",
      "|    0   N/A  N/A      1413      G   /usr/bin/gnome-shell              115MiB |\n",
      "|    0   N/A  N/A      2094      G   /usr/lib/xorg/Xorg                402MiB |\n",
      "|    0   N/A  N/A      2226      G   /usr/bin/gnome-shell               49MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f364d8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "## GPU check\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3977bd",
   "metadata": {},
   "source": [
    "### 3.1. Positional Embedding (input, output)\n",
    "Token Embedding + Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "759d72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, device=DEVICE, maxlen=5000):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, emb_size) #(128, 17, 5)\n",
    "        \n",
    "        pos = torch.arange(0,maxlen).reshape(maxlen,1).to(device)\n",
    "        #pos = pos.to(device='cuda')\n",
    "        two_i = torch.arange(0,emb_size,2).to(device)\n",
    "        #two_i = two_i.to(device='cuda')\n",
    "        \n",
    "        self.pos_encoding = torch.zeros((maxlen, emb_size))\n",
    "        self.pos_encoding = self.pos_encoding.to(device)\n",
    "        self.pos_encoding.requires_grad= False\n",
    "        \n",
    "        self.pos_encoding[:,0::2] = torch.sin(pos/ (10000**(two_i/emb_size))) #짝수 index\n",
    "        self.pos_encoding[:,1::2] = torch.cos(pos/ (10000**(two_i/emb_size))) # 홀수 index\n",
    "        \n",
    "    def forward(self, x):\n",
    "        try:\n",
    "            sen_length = x.shape[1] #(batch_size, seq_len, emb_size) 3d tensor 기준\n",
    "        except:\n",
    "            sen_length = x.shape[0]\n",
    "        return self.token_embedding(x) + self.pos_encoding[:sen_length,:]       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf4fbbc",
   "metadata": {},
   "source": [
    "### 3.2. Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac4e072",
   "metadata": {},
   "source": [
    "`torch.nn.Transformer`: https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ab3012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seqTransformer(nn.Module):\n",
    "    def __init__(self, n_head, n_enc_layers, n_dec_layers,\n",
    "                emb_size, src_vocab_size, trg_vocab_size,\n",
    "                d_ffn, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.src_pos_embedding = PositionalEmbedding(src_vocab_size, emb_size)\n",
    "        self.trg_pos_embedding = PositionalEmbedding(trg_vocab_size, emb_size)\n",
    "        \n",
    "        \n",
    "        self.transformer = Transformer(d_model = emb_size, nhead = n_head,\n",
    "                                       num_encoder_layers = n_enc_layers,\n",
    "                                       num_decoder_layers = n_dec_layers,\n",
    "                                       dim_feedforward = d_ffn, dropout = dropout,\n",
    "                                       custom_encoder=None, custom_decoder=None,\n",
    "                                       layer_norm_eps=1e-05, batch_first=True) # batch_First = False(Default)\n",
    "        \n",
    "        self.translator = nn.Linear(emb_size, trg_vocab_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, src, trg, src_mask, trg_mask,\n",
    "                src_padding_mask, trg_padding_mask,\n",
    "                memory_key_padding_mask):\n",
    "\n",
    "        src_emb = self.src_pos_embedding(src)\n",
    "        trg_emb = self.trg_pos_embedding(trg)\n",
    "\n",
    "        output = self.transformer(src_emb, trg_emb, src_mask, trg_mask, None,\n",
    "                                  src_padding_mask, trg_padding_mask, memory_key_padding_mask)\n",
    "        \n",
    "        return self.translator(output)\n",
    "    \n",
    "    \n",
    "    ## test 용도(for greedy decoder)\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.transformer.encoder(self.src_pos_embedding(src), src_mask)\n",
    "    \n",
    "    def decode(self, trg, memory, trg_mask):\n",
    "        return self.transformer.decoder(self.trg_pos_embedding(trg), memory, trg_mask) # memory: encoder output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cff5191",
   "metadata": {},
   "source": [
    "### 3.3. Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b0c34b",
   "metadata": {},
   "source": [
    "N=batch_size, S= source length, T= target length, E=embedding dim\n",
    "\n",
    "- src: :math:`(S, N, E)`, `(N, S, E)` if batch_first.\n",
    "- tgt: :math:`(T, N, E)`, `(N, T, E)` if batch_first.\n",
    "- src_mask: :math:`(S, S)`.\n",
    "- tgt_mask: :math:`(T, T)`.\n",
    "- memory_mask: :math:`(T, S)`.\n",
    "- src_key_padding_mask: :math:`(N, S)`.\n",
    "- tgt_key_padding_mask: :math:`(N, T)`.\n",
    "- memory_key_padding_mask: :math:`(N, S)`.\n",
    "\n",
    "`torch.triu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30455212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.triu(torch.ones((10,10), device=DEVICE)) == 1).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "daf7bf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (torch.triu(torch.ones((10, 10), device=DEVICE)) == 1).transpose(0, 1)\n",
    "mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe7c20",
   "metadata": {},
   "source": [
    "위와 같이 예측 시점의 이후 시점들에 대해서는 모두 -inf로 마스킹 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f5c135a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,  177,   15,  ...,    1,    1,    1],\n",
       "        [   2,  228,    6,  ...,    1,    1,    1],\n",
       "        [   2,  806,   38,  ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   2,   17, 1963,  ...,    1,    1,    1],\n",
       "        [   2,    7,   53,  ...,    1,    1,    1],\n",
       "        [   2,  116,   15,  ...,    1,    1,    1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "114f8ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ex[0] == PAD_IDX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49fd001",
   "metadata": {},
   "source": [
    "위와 같이 batch 별로 padding 위치에 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a84b1803",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 미래 시점 참고 못하도록 마스킹\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "## 패딩 마스킹, subsequent 마스킹\n",
    "def create_mask(src, trg):\n",
    "    src_seq_len = src.shape[1]\n",
    "    trg_seq_len = trg.shape[1]\n",
    "\n",
    "    trg_mask = generate_square_subsequent_mask(trg_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX)\n",
    "    trg_padding_mask = (trg == PAD_IDX)\n",
    "    \n",
    "    #src_padding_mask = (src == PAD_IDX).transpose(0, 1) # batch_first = False\n",
    "    #trg_padding_mask = (trg == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, trg_mask, src_padding_mask, trg_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb101ae",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c14706cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0) #랜덤 시드 고정\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_dict[src_lang])\n",
    "TRG_VOCAB_SIZE = len(vocab_dict[trg_lang])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "\n",
    "## 모델 선언\n",
    "transformer = seq2seqTransformer(NHEAD, NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 SRC_VOCAB_SIZE, TRG_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "\n",
    "## CE Loss 정의(패딩 부분은 무시하도록)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14239fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    train_dataloader = DataLoader(train_pairs, batch_size=128, collate_fn=custom_collate_fn)\n",
    "\n",
    "    for src, trg in train_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        trg = trg.to(DEVICE)\n",
    "\n",
    "        trg_input = trg[:, :-1] # batch_first=True\n",
    "        ## trg_input = trg[:-1, :] # batch_first=False (sent_length, batch_size)\n",
    "\n",
    "        src_mask, trg_mask, src_padding_mask, trg_padding_mask = create_mask(src, trg_input)\n",
    "\n",
    "        \n",
    "        logits = model(src, trg_input, src_mask, trg_mask, src_padding_mask, trg_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        trg_out = trg[:, 1:]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), trg_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aaa8b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    val_dataloader = DataLoader(val_pairs, batch_size=BATCH_SIZE, collate_fn=custom_collate_fn)\n",
    "\n",
    "    for src, trg in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        trg = trg.to(DEVICE)\n",
    "\n",
    "        trg_input = trg[:, :-1]\n",
    "\n",
    "        src_mask, trg_mask, src_padding_mask, trg_padding_mask = create_mask(src, trg_input)\n",
    "\n",
    "        logits = model(src, trg_input, src_mask, trg_mask, src_padding_mask, trg_padding_mask, src_padding_mask)\n",
    "\n",
    "        trg_out = trg[:, 1:]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), trg_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "48430649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 1.471, Val loss: 1.501, Epoch time = 38.075s\n",
      "Epoch: 2, Train loss: 1.326, Val loss: 1.413, Epoch time = 38.314s\n",
      "Epoch: 3, Train loss: 1.206, Val loss: 1.362, Epoch time = 38.569s\n",
      "Epoch: 4, Train loss: 1.100, Val loss: 1.327, Epoch time = 38.544s\n",
      "Epoch: 5, Train loss: 1.008, Val loss: 1.291, Epoch time = 38.429s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# training start!\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "\n",
    "\n",
    "# after traing -> save model.pth\n",
    "path = \"model/\"\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "torch.save(transformer, path+'transformer.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f86c441",
   "metadata": {},
   "source": [
    "## 5. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4660c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 저장해둔 trasnforemr model 로드\n",
    "\n",
    "model = torch.load(path+'transformer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e4d6d783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test용 greedy decoder\n",
    "## <BOS>를 시작으로 target token 하나씩 들어가면서 max_prob인 토큰 반환\n",
    "## <EOS> 나오면 종료\n",
    "\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    \n",
    "    src = src.to(DEVICE) #runtime error 방지\n",
    "    src_mask = src_mask.to(DEVICE) #runtime error 방지\n",
    "\n",
    "    memory = model.encode(src, src_mask) # transformer.encode\n",
    "    result = torch.ones(1,1).fill_(start_symbol).type(torch.long).to(DEVICE) # 초기 result: BOS_IDX(2)로만 이루어진 (1,1) tensor\n",
    "    \n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE) \n",
    "        trg_mask = (generate_square_subsequent_mask(result.size(0)).type(torch.bool)).to(DEVICE)\n",
    "        result1 = result.transpose(0,1) ## batch_first=False -> x required\n",
    "        out = model.decode(result1, memory, trg_mask) # transformer.decode\n",
    "        ## out = out.transpose(0, 1) ## batch_first=False\n",
    "        prob = model.translator(out[:, -1]) #(1,512) -> (1,vocab_size)\n",
    "        _, next_word = torch.max(prob, dim=1) # (1,vocab_size) tensor 내 가장 큰 값 추출\n",
    "        next_word = next_word.item() # 단어 인덱스\n",
    "        \n",
    "        result = torch.cat([result, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0) # next_word 추가\n",
    "        \n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "09597be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역문 생성 함수\n",
    "\n",
    "def translate(model, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = txt_to_tensor(src_sentence, src_lang).unsqueeze(0) # 3d tensor\n",
    "    ## src = txt_to_tensor(src_sentence, src_lang) ## batch_first=False\n",
    "    num_tokens = src.shape[1]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    trg_tokens = greedy_decode(model, src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_dict[trg_lang].lookup_tokens(list(trg_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735544f7",
   "metadata": {},
   "source": [
    "### 번역 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9462caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(sent_num, pairs):\n",
    "    print(f\"Spanish: {pairs[sent_num][0]} \\n Translation to English: {translate(model, pairs[sent_num][0])} \\n Original English: {pairs[sent_num][1]}\")\n",
    "    print(\"=====\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "63c3c0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish: El automóvil se detuvo. \n",
      " Translation to English:  The car stopped .  \n",
      " Original English: The automobile stopped.\n",
      "==================================================\n",
      "Spanish: Yo lo vi, también. \n",
      " Translation to English:  I saw it , too .  \n",
      " Original English: I saw it, too.\n",
      "==================================================\n",
      "Spanish: Tom dejó solos a Mary y John momentáneamente. \n",
      " Translation to English:  Tom left Mary and John kissing .  \n",
      " Original English: Tom left Mary and John alone momentarily.\n",
      "==================================================\n",
      "Spanish: Sos mi amiga. \n",
      " Translation to English:  You 're my friend .  \n",
      " Original English: You're my friend.\n",
      "==================================================\n",
      "Spanish: Deshazte del arma. \n",
      " Translation to English:  You look gun .  \n",
      " Original English: Get rid of the gun.\n",
      "==================================================\n",
      "Spanish: Tom no es tan malo como Mary piensa que es. \n",
      " Translation to English:  Tom is n't as bad as Mary is .  \n",
      " Original English: Tom isn't as bad as Mary thinks he is.\n",
      "==================================================\n",
      "Spanish: Él corrió tan rápidamente como pudo. \n",
      " Translation to English:  He ran as fast as he could .  \n",
      " Original English: He ran as fast as he could.\n",
      "==================================================\n",
      "Spanish: ¿Se siente usted bien hoy? \n",
      " Translation to English:  Are you feeling good today ?  \n",
      " Original English: Are you feeling all right today?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i in [33,37,73,77,602,1123,1998,8888]:\n",
    "    get_result(i, test_pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
