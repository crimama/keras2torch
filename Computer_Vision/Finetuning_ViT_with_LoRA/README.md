# Finetuning ViT with LoRA

- **Author**: Jaehyuk Heo
- **Paper**: LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS [ [link](https://arxiv.org/pdf/2106.09685.pdf) ]
- **Official Github**: https://github.com/microsoft/LoRA#L12-L29


# Method

<p align='center'>
    <img width='400' src='https://user-images.githubusercontent.com/37654013/168552268-c764cb0c-2684-4082-a633-ba2d8cf340a3.png'>
</p>


# Results

**Performance**

<p align='center'>
    <img width='1000' src='https://user-images.githubusercontent.com/37654013/168573159-37afb6ec-a7d5-4dab-8604-781ab2f83cc0.png'>
</p>


**Memory Allocation**

<p align='center'>
    <img width='1000' src='https://user-images.githubusercontent.com/37654013/168573658-5f0299ec-b68c-474a-8540-3a9246c2ec7f.png'>
</p>